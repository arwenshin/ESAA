{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week4_핸즈온 머신러닝(앙상블 학습과 랜덤 포레스트).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM9Zhd10kfVUlmYELqj7F84"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**CHAPTER 07 앙상블 학습과 랜덤 포레스트**\n"],"metadata":{"id":"510NA3zimtEu"}},{"cell_type":"markdown","source":["##7.1 투표 기반 분류기"],"metadata":{"id":"FtY5ZvvAm2Vw"}},{"cell_type":"markdown","source":["\n","\n","*   직접 투표 : 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측 (다수결 투표)\n","\n","다수결 투표 분류기가 앙상블에 포함된 개별 분류기 중 가장 뛰어난 것보다도 정확도가 높은 경우가 많다. 약한 학습기일지라도 충분하게 많고 다양하다면 앙상블은 높은 정확도를 내는 강한 학습기가 될 수 있다.\n"],"metadata":{"id":"ZEjOSq02m7J1"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"y9w2s6BekTZk","executionInfo":{"status":"ok","timestamp":1648438967557,"user_tz":-540,"elapsed":284,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}}},"outputs":[],"source":["from sklearn.datasets import make_moons\n","\n","X,y = make_moons(n_samples = 10000, noise = 0.4)"]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"groWOL5-sgaL","executionInfo":{"status":"ok","timestamp":1648440253549,"user_tz":-540,"elapsed":347,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"77028c16-9898-4273-adff-004e607398e2"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 2)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdaxAWvGslMF","executionInfo":{"status":"ok","timestamp":1648440270035,"user_tz":-540,"elapsed":288,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"3ba73a09-75fe-4392-d7b2-255890acb2eb"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.63441421, -0.70457056],\n","       [-0.08932533,  0.23436512],\n","       [ 1.91649693,  0.16352908],\n","       ...,\n","       [ 1.37509635, -0.60449646],\n","       [ 0.19503503,  0.39852302],\n","       [-0.45866247,  0.79522327]])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8V5M8C4siEx","executionInfo":{"status":"ok","timestamp":1648440265330,"user_tz":-540,"elapsed":268,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"920d37ec-9cfb-4513-f005-dd9a356d5f81"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000,)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"],"metadata":{"id":"d8Mfh2mek996","executionInfo":{"status":"ok","timestamp":1648438992048,"user_tz":-540,"elapsed":596,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2H1XfNUssnTN","executionInfo":{"status":"ok","timestamp":1648440280931,"user_tz":-540,"elapsed":3,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"e3095199-eb91-42ff-a927-7d171bd96a0d"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8000, 2)"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["여러 분류기를 조합하여 사이킷런의 투표 기반 분류기(VotingClassifier)를 만들어 훈련시켜보자"],"metadata":{"id":"kjoDBp2umsGN"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","log_clf = LogisticRegression()\n","rnd_clf = RandomForestClassifier()\n","svm_clf = SVC()\n","\n","voting_clf = VotingClassifier(\n","    estimators = [('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)],\n","    voting = 'hard')\n","voting_clf.fit(X_train,y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UX3PqyPLlR3t","executionInfo":{"status":"ok","timestamp":1648438996173,"user_tz":-540,"elapsed":2572,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"c61756dd-d233-47c0-c9bb-bb33b6f14e72"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VotingClassifier(estimators=[('lr', LogisticRegression()),\n","                             ('rf', RandomForestClassifier()), ('svc', SVC())])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","for clf in (log_clf,rnd_clf,svm_clf, voting_clf):\n","    clf.fit(X_train,y_train)\n","    y_pred = clf.predict(X_test)\n","    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyrGwOf8l76F","executionInfo":{"status":"ok","timestamp":1648439003053,"user_tz":-540,"elapsed":5622,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"5be31a4a-352f-4468-ba1d-5e350690bf76"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["LogisticRegression 0.827\n","RandomForestClassifier 0.8505\n","SVC 0.861\n","VotingClassifier 0.855\n"]}]},{"cell_type":"markdown","source":["투표 기반 분류기가 다른 개별 분류기보다 성능이 조금 높다."],"metadata":{"id":"Na3tCzHami_F"}},{"cell_type":"markdown","source":["##7.2 배깅과 페이스팅"],"metadata":{"id":"z9MznkrAn8PX"}},{"cell_type":"markdown","source":["\n","\n","\n","\n","*   **배깅(bootstrap aggregating 의 줄임말)** : 훈련 세트에서 중복을 허용하여 샘플링하는 방식\n","*   **페이스팅(pasting)** : 중복을 허용하지 않고 샘플링하는 방식\n","\n"],"metadata":{"id":"sGyduBFVn_Ns"}},{"cell_type":"markdown","source":["수집함수는   \n","'분류' 일 때는 통계적 최빈값  \n","'회귀' 일 때는 평균 계산  \n","\n","개별 예측기는 원본 훈련 세트로 훈련시킨 것보다 훨씬 크게 편향되어 있지만  \n","수집 함수를 통과하면 편향과 분산이 모두 감소한다. 일반적으로 앙상블의 결과는 원본 데이터셋으로 하나의 예측기를 훈련시킬 때와 비교해 편향은 비슷하지만 분산은 줄어든다."],"metadata":{"id":"BmBBWwR_oVGn"}},{"cell_type":"markdown","source":["###7.2.1 사이킷런의 배깅과 페이스팅"],"metadata":{"id":"TfPC_9O2ozsF"}},{"cell_type":"markdown","source":["결정 트리 분류기 500개의 앙상블을 훈련시켜보자.  \n","각 분류기는 훈련 세트에서 중복을 허용하여 무작위로 선택된 100개의 샘플로 훈련된다.( 이는 배깅의 경우이고, 대신 페이스팅을 사용하려면 bootstrap = False로 지정하면 된다.) n_jogs 매개변수는 사이킷런이 훈련과 예측에 사용할 CPU 코어 수를 지정한다.\n","\n"],"metadata":{"id":"5Be1zgz4p_77"}},{"cell_type":"code","source":["from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","bag_clf = BaggingClassifier(\n","    DecisionTreeClassifier(), n_estimators = 500,\n","    max_samples = 100, bootstrap = True, n_jobs = -1)\n","\n","bag_clf.fit(X_train,y_train)\n","y_pred = bag_clf.predict(X_test)"],"metadata":{"id":"55-DW7ksmSQ3","executionInfo":{"status":"ok","timestamp":1648439447844,"user_tz":-540,"elapsed":3978,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["###7.2.2 oob 평가"],"metadata":{"id":"nqOj68aEqxy3"}},{"cell_type":"markdown","source":["**oob(out-of-bag) 샘플** : 배깅 과정에서 선택되지 않은 훈련 샘플들  \n","예측기가 훈련되는 동안에는 oob 샘플을 사용하지 않으므로 별도의 검증 세트를 사용하지 않고 oob 샘플을 사용해 평가할 수 있다.  \n","**앙상블의 평가는 각 에측기의 oob 평가를 평균하여 얻는다.**"],"metadata":{"id":"8FJEJVW1rJKz"}},{"cell_type":"code","source":["bag_clf = BaggingClassifier(\n","    DecisionTreeClassifier(),n_estimators = 500,\n","    bootstrap = True, n_jobs= -1, oob_score = True)\n","\n","bag_clf.fit(X_train,y_train)\n","bag_clf.oob_score_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1OGEvl7pYJE","executionInfo":{"status":"ok","timestamp":1648439892035,"user_tz":-540,"elapsed":10138,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"e1e14c68-49ef-4d33-a1bd-5edb28e5759b"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.841875"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["oob 평가 결과를 보면 이 BaggingClassifier는 테스트 세트에서 약 84% 의 정확도를 얻을 것으로 보인다."],"metadata":{"id":"Ed_4ykSWrlxq"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score \n","y_pred = bag_clf.predict(X_test)\n","accuracy_score(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZ-dOHe7rGws","executionInfo":{"status":"ok","timestamp":1648440080397,"user_tz":-540,"elapsed":1657,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"8989b119-5ae9-4e3c-9381-fdac39635459"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8445"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["테스트 세트에서 84% 의 정확도를 얻었다. 매우 비슷한 수치이다."],"metadata":{"id":"Eb66rNARr4Pl"}},{"cell_type":"markdown","source":["\n","\n","*   **oob_decision_function_** : oob 샘플에 대한 결정 함수의 값 확인  \n","각 훈련 샘플의 클래스 확률을 반환한다.(기반이 되는 예측기가 predict_proba() 메서드를 가지고 있기 때문에)\n","\n"],"metadata":{"id":"VWeBkReHsAGq"}},{"cell_type":"code","source":["bag_clf.oob_decision_function_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JduUSzfRr2tE","executionInfo":{"status":"ok","timestamp":1648440229552,"user_tz":-540,"elapsed":6,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"364d567c-0181-4e3c-c6bd-74a83bbc25f8"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.25988701, 0.74011299],\n","       [1.        , 0.        ],\n","       [1.        , 0.        ],\n","       ...,\n","       [0.66829268, 0.33170732],\n","       [0.        , 1.        ],\n","       [0.        , 1.        ]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["bag_clf.oob_decision_function_.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LN4BUYcxsbsA","executionInfo":{"status":"ok","timestamp":1648440240735,"user_tz":-540,"elapsed":310,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"d6cf9622-a5c9-47d9-edae-10f8e7191272"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8000, 2)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["oob 평가는 첫 번째 훈련 샘플이 양성 클래스에 속할 확률을 74.01% 로 추정하고 있다."],"metadata":{"id":"nuqWSV-Vsq3M"}},{"cell_type":"markdown","source":["##7.3 랜덤 패치와 랜덤 서브스페이스"],"metadata":{"id":"EK8mRGyus1A9"}},{"cell_type":"markdown","source":["BaggingClassifier는 특성 샘플링도 지원한다. 따라서 각 예측기는 무작위로 선택한 입력 특성의 일부분으로 훈련된다.  \n","\n","이 기법은 매우 고차원의 데이터셋을 다룰 때 유용하다."],"metadata":{"id":"kMbfj3YCs59m"}},{"cell_type":"markdown","source":["\n","\n","*   **랜덤 패치 방식** : 훈련 특성과 샘플을 모두 샘플링하는 것\n","*   **랜덤 서브스페이스 방식** : 훈련 샘플을 모두 사용하고 특성은 샘플링하는 것  \n","\n","특성 샘플링은 더 다양한 예측기를 만들며 편향을 늘리는 대신 분산을 낮춘다.\n","\n","\n","\n"],"metadata":{"id":"87bHlasatJOn"}},{"cell_type":"markdown","source":["##7.4 랜덤 포레스트"],"metadata":{"id":"0qwaIgIbthfw"}},{"cell_type":"markdown","source":["랜덤 포레스트는 일반적으로 배깅 방법(또는 페이스팅)을 적용한 결정 트리의 앙상블이다."],"metadata":{"id":"c53gr2Qjtld1"}},{"cell_type":"markdown","source":["최대 16개의 리프 토드를 갖는 500개의 트리로 이뤄진 랜덤 포레스트 분류기를 여러 CPU 코어에서 훈련시켜보자"],"metadata":{"id":"UJyA1pmLtr4T"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rnd_clf = RandomForestClassifier(n_estimators= 500, max_leaf_nodes = 16, n_jobs = -1)\n","rnd_clf.fit(X_train,y_train)\n","\n","y_pred_rf = rnd_clf.predict(X_test)"],"metadata":{"id":"tsZb2D8zseUw","executionInfo":{"status":"ok","timestamp":1648440683363,"user_tz":-540,"elapsed":5153,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["y_pred_rf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzrSDxXuuJUW","executionInfo":{"status":"ok","timestamp":1648440687152,"user_tz":-540,"elapsed":258,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"7032d060-8c62-4a2e-93f7-fc918b690746"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, ..., 1, 1, 0])"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["랜덤 포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 차즌 식으로 무작위성을 더 주입한다. 결국 트리를 더욱 다양하게 만들고 편향을 손해보는 대신 분산을 낮추어 전체적으로 더 훌륭한 모델을 만들어낸다."],"metadata":{"id":"AN1EUYgJuQdB"}},{"cell_type":"markdown","source":["BaggingClassifier를 사용해 앞의 RandomForestClassifier와 거의 유사하게 만들어 보자"],"metadata":{"id":"07zcl6yiukpU"}},{"cell_type":"code","source":["bag_clf = BaggingClassifier(\n","    DecisionTreeClassifier(max_features ='auto', max_leaf_nodes = 16), n_estimators = 500, max_samples = 1.0, bootstrap =True, n_jobs=-1)"],"metadata":{"id":"htxJBStXuLb1","executionInfo":{"status":"ok","timestamp":1648440925433,"user_tz":-540,"elapsed":298,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["###7.4.2 특성 중요도"],"metadata":{"id":"O1v1JitSvGkV"}},{"cell_type":"markdown","source":["사이킷런은 어떤 특성을 사용한 노드가 (랜덤 포레스트에 있는 모든 트리에 걸쳐서) 평균적으로 불순도를 얼마나 감소시키는지 확인하여 특성의 중요도를 측정한다.  \n","더 정확히 말하면 가중치 평균이며 각 노드의 가중치는 연관된 훈련 샘플 수와 같다."],"metadata":{"id":"MnMCxvsXySc0"}},{"cell_type":"markdown","source":["사이킷런은 훈련이 끝난 뒤 특성마다 자동으로 이 점수를 계산하고 중요도의 전체 합이 1이 되도록 결괏값을 정규화함."],"metadata":{"id":"Jo171HZsyzTG"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","iris = load_iris()\n","rnd_clf = RandomForestClassifier(n_estimators =500,n_jobs = -1)\n","rnd_clf.fit(iris['data'],iris['target'])\n","for name,score in zip(iris['feature_names'],rnd_clf.feature_importances_):\n","    print(name,score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xIr2mzlu38z","executionInfo":{"status":"ok","timestamp":1648442031428,"user_tz":-540,"elapsed":1846,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"0f1a08df-7783-495a-87cd-5a0c9d7e6b9d"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["sepal length (cm) 0.09876374559148975\n","sepal width (cm) 0.024927936342367733\n","petal length (cm) 0.4325520614507921\n","petal width (cm) 0.44375625661535056\n"]}]},{"cell_type":"markdown","source":["가장 중요한 특성은 꽃잎의 길이(43%) 와 너비(43%) 이고 꽃받침의 길이와 너비는 비교적 덜 중요해보인다."],"metadata":{"id":"7O3dVt4vzUv3"}},{"cell_type":"markdown","source":["#7.5 부스팅"],"metadata":{"id":"q-cnS5QNzi0e"}},{"cell_type":"markdown","source":["**부스팅** : 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법. 앞의 모델을 보완해가면서 일련의 예측기를 학습시킨다."],"metadata":{"id":"c-y-VSKazom4"}},{"cell_type":"markdown","source":["##7.5.1 에이다부스트"],"metadata":{"id":"BaxDJsECzyem"}},{"cell_type":"markdown","source":["1. 알고리즘의 기반이 되는 첫번째 분류기를 훈련 세트에서 훈련시키고 예측을 만든다.  \n","2. 알고리즘이 잘못 분류된 훈련 샘플의 가중치를 상대적으로 높인다.  \n","3. 두 번째 분류기는 업데이트된 가중치를 사용해 훈련 세트에서 훈련하고 다시 예측을 만든다.  \n","4. 다시 가중치를 업데이트한다."],"metadata":{"id":"kmS1NCIvz5IH"}},{"cell_type":"markdown","source":["200개의 아주 얕은 결정 트리를 기반으로 하는 에이다부스트 분류기를 훈련시켜보자. 여기서 사용하는 결정 트리는 max_depth = 1로 결정 노드 하나와 리프노드 두 개로 이루어진 트리이다."],"metadata":{"id":"mEgbJU2U0ec4"}},{"cell_type":"code","source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","ada_clf = AdaBoostClassifier(\n","    DecisionTreeClassifier(max_depth = 1), n_estimators = 200,\n","    algorithm = 'SAMME.R',learning_rate= 0.5)\n","ada_clf.fit(X_train,y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLk7uez7zRCR","executionInfo":{"status":"ok","timestamp":1648442854801,"user_tz":-540,"elapsed":1983,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"36a10ced-15df-4103-a2b9-48f0632890d1"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n","                   learning_rate=0.5, n_estimators=200)"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["###7.5.2 그레이디언트 부스팅"],"metadata":{"id":"V2gfqQmF76ta"}},{"cell_type":"markdown","source":["**그레이디언트 부스팅** : 이전 예측기가 만든 잔여 오차(residual error)에 새로운 예측기를 학습시킨다."],"metadata":{"id":"yN6Cxeey7_zm"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","\n","tree_reg1 = DecisionTreeRegressor(max_depth=2)\n","tree_reg1.fit(X,y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OwumMWk2cI8","executionInfo":{"status":"ok","timestamp":1648444401077,"user_tz":-540,"elapsed":301,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"c2f6cd09-9b35-428b-e52d-1a64109ee581"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeRegressor(max_depth=2)"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["첫 번째 예측기에서 생긴 잔여 오차에 두 번째 DecisionTreeRegressor를 훈련시킨다."],"metadata":{"id":"BrlBJFKJ8imu"}},{"cell_type":"code","source":["y2 = y - tree_reg1.predict(X)\n","tree_reg2 = DecisionTreeRegressor(max_depth=2)\n","tree_reg2.fit(X,y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSskycze8WDQ","executionInfo":{"status":"ok","timestamp":1648444446298,"user_tz":-540,"elapsed":319,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"c1b1c941-37ed-40e4-ba90-ae1f99ef07f2"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeRegressor(max_depth=2)"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["두 번째 예측기가 만든 잔여 오차에 세 번째 회귀 모델을 훈련시킨다."],"metadata":{"id":"1PhnKjYy8pXe"}},{"cell_type":"code","source":["y3 = y2 - tree_reg2.predict(X)\n","tree_reg3 = DecisionTreeRegressor(max_depth=2)\n","tree_reg3.fit(X,y3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UqDnp5S-8dm8","executionInfo":{"status":"ok","timestamp":1648444536858,"user_tz":-540,"elapsed":313,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"18f6dc76-f680-4b16-fa18-994494b10651"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeRegressor(max_depth=2)"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["이제 세 개의 트리를 포함하는 앙상블 모델이 생겼다. 새로운 샘플에 대한 예측을 만들려면 모든 트리의 예측을 더하면 된다."],"metadata":{"id":"5q82IXw0849U"}},{"cell_type":"code","source":["y_pred = sum(tree.predict(X_new) for tree in (tree_reg1,tree_reg2,tree_reg3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"8QKHFy7Y83Sw","executionInfo":{"status":"error","timestamp":1648444618074,"user_tz":-540,"elapsed":297,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"8f2aa82b-6485-43d1-d471-0372b399f8a7"},"execution_count":40,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-653af8af30b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtree_reg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree_reg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree_reg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-40-653af8af30b3>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtree_reg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree_reg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree_reg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_new' is not defined"]}]},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingRegressor\n","\n","gbrt = GradientBoostingRegressor(max_depth=2, n_estimators =3, learning_rate =1.0)\n","gbrt.fit(X,y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBSCgCae9I-T","executionInfo":{"status":"ok","timestamp":1648444692035,"user_tz":-540,"elapsed":303,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"a2e79949-dd74-4554-f13a-5d821fe9fe5a"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["\n","\n","*   learning_rate : 각 트리의 기여 정도<br>  \n","축소 기법: 0.1처럼 낮게 설정하면 앙상블을 훈련 세트에 학습시키기 위해 많은 트리가 필요하지만 일반적으로 예측의 성능은 좋아진다.\n","\n"],"metadata":{"id":"TVYY5FgF9e_Q"}},{"cell_type":"markdown","source":["최적의 트리 수를 찾는 방법 -> **조기 종료 기법**"],"metadata":{"id":"zDfbsSfv97V7"}},{"cell_type":"markdown","source":["120개의 트리로 GBRT 앙상블을 훈련시키고 최적의 트리 수를 찾기 위해 각 훈련 단계에서 검증 오차를 측정한다. 마지막에 최적의 트리 수를 사용해 새로운 GBRT 앙상블을 훈련시킨다."],"metadata":{"id":"g12prbto-Cqb"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","X_train,X_val,y_train,y_val = train_test_split(X,y)\n","\n","gbrt = GradientBoostingRegressor(max_depth=2,n_estimators=120)\n","gbrt.fit(X_train,y_train)\n","\n","errors = [mean_squared_error(y_val,y_pred) for y_pred in gbrt.staged_predict(X_val)]\n","bst_n_estimators = np.argmin(errors)+1\n","\n","gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators = bst_n_estimators)\n","gbrt_best.fit(X_train,y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtaEhnJy9dIx","executionInfo":{"status":"ok","timestamp":1648445059690,"user_tz":-540,"elapsed":2115,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"6cd99d5a-5c0a-42b5-93ba-3d4fd4d1a7be"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GradientBoostingRegressor(max_depth=2, n_estimators=120)"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["실제로 훈련을 중지하는 방법으로 조기 종료를 구현할 수도 있다.  \n","\n","warm_start = True 로 설정하면 사이킷런이 fit() 메서드가 호출될 때 기존 트리를 유지하고 훈련을 추가할 수 있도록 해준다. 다음 코드는 연속해서 다섯 번의 반복동안 검증 오차가 향상되지 않으면 훈련을 멈춘다."],"metadata":{"id":"Wrxl7RV-_L4z"}},{"cell_type":"code","source":["gbrt = GradientBoostingRegressor(max_depth=2, warm_start = True)\n","\n","min_val_error = float('inf')\n","error_going_up = 0\n","for n_estimators in range(1,120):\n","    gbrt.n_estimators = n_estimators\n","    gbrt.fit(X_train,y_train)\n","    y_pred = gbrt.predict(X_val)\n","    val_error = mean_squared_error(y_val,y_pred)\n","    if val_error < min_val_error:\n","        min_val_error = val_error\n","        error_going_up = 0\n","    else:\n","        error_going_up += 1\n","        if error_going_up == 5:\n","            break   #조기 종료"],"metadata":{"id":"pAiiK4k_-2c5","executionInfo":{"status":"ok","timestamp":1648445412630,"user_tz":-540,"elapsed":2823,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["<확률적 그레이디언트 부스팅>\n","\n","*   **subsample** : 각 트리가 훈련할 때 사용할 훈련 샘플의 비율 지정  \n","예를 들어 subsmaple = 0.25 라고 하면 각 트리는 무작위로 선택된 25%의 훈련 샘플로 학습된다. 편향이 높아지는 대신 분산이 낮아지게 된다. 또한 훈련 속도도 상당히 높아진다.\n","\n"],"metadata":{"id":"eY7xMgvqAPKu"}},{"cell_type":"markdown","source":["<XGBoost> : 쵲거화된 그레이디언트 부스팅 구현"],"metadata":{"id":"ghyNADbpAxmn"}},{"cell_type":"code","source":["import xgboost \n","xgb_reg = xgboost.XGBRegressor()\n","xgb_reg.fit(X_train,y_train)\n","y_pred = xgb_reg.predict(X_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uuuBwbtGAISi","executionInfo":{"status":"ok","timestamp":1648445624925,"user_tz":-540,"elapsed":577,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"0c92c620-dff7-48f6-dd25-4af18c6a856b"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[05:33:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"]}]},{"cell_type":"code","source":["xgb_reg.fit(X_train,y_train,eval_set=[(X_val,y_val)], early_stopping_rounds =2)\n","y_pred = xgb_reg.predict(X_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cBvODk2BAze","executionInfo":{"status":"ok","timestamp":1648446538316,"user_tz":-540,"elapsed":575,"user":{"displayName":"­신선민(자연과학대학 통계학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15538581907388309584"}},"outputId":"7cada86f-1546-492a-94d4-f951d155d253"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["[05:48:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[0]\tvalidation_0-rmse:0.47354\n","Will train until validation_0-rmse hasn't improved in 2 rounds.\n","[1]\tvalidation_0-rmse:0.450841\n","[2]\tvalidation_0-rmse:0.43156\n","[3]\tvalidation_0-rmse:0.415299\n","[4]\tvalidation_0-rmse:0.401226\n","[5]\tvalidation_0-rmse:0.389469\n","[6]\tvalidation_0-rmse:0.379336\n","[7]\tvalidation_0-rmse:0.370766\n","[8]\tvalidation_0-rmse:0.363586\n","[9]\tvalidation_0-rmse:0.35768\n","[10]\tvalidation_0-rmse:0.352678\n","[11]\tvalidation_0-rmse:0.34838\n","[12]\tvalidation_0-rmse:0.344557\n","[13]\tvalidation_0-rmse:0.341534\n","[14]\tvalidation_0-rmse:0.33889\n","[15]\tvalidation_0-rmse:0.336888\n","[16]\tvalidation_0-rmse:0.334906\n","[17]\tvalidation_0-rmse:0.333266\n","[18]\tvalidation_0-rmse:0.331862\n","[19]\tvalidation_0-rmse:0.330816\n","[20]\tvalidation_0-rmse:0.329794\n","[21]\tvalidation_0-rmse:0.328656\n","[22]\tvalidation_0-rmse:0.327826\n","[23]\tvalidation_0-rmse:0.326933\n","[24]\tvalidation_0-rmse:0.326097\n","[25]\tvalidation_0-rmse:0.325466\n","[26]\tvalidation_0-rmse:0.324851\n","[27]\tvalidation_0-rmse:0.324373\n","[28]\tvalidation_0-rmse:0.32386\n","[29]\tvalidation_0-rmse:0.32347\n","[30]\tvalidation_0-rmse:0.323006\n","[31]\tvalidation_0-rmse:0.322696\n","[32]\tvalidation_0-rmse:0.322376\n","[33]\tvalidation_0-rmse:0.322109\n","[34]\tvalidation_0-rmse:0.321809\n","[35]\tvalidation_0-rmse:0.321656\n","[36]\tvalidation_0-rmse:0.321412\n","[37]\tvalidation_0-rmse:0.321284\n","[38]\tvalidation_0-rmse:0.321094\n","[39]\tvalidation_0-rmse:0.320932\n","[40]\tvalidation_0-rmse:0.320841\n","[41]\tvalidation_0-rmse:0.320664\n","[42]\tvalidation_0-rmse:0.32057\n","[43]\tvalidation_0-rmse:0.320507\n","[44]\tvalidation_0-rmse:0.320364\n","[45]\tvalidation_0-rmse:0.320277\n","[46]\tvalidation_0-rmse:0.320221\n","[47]\tvalidation_0-rmse:0.320144\n","[48]\tvalidation_0-rmse:0.320082\n","[49]\tvalidation_0-rmse:0.320036\n","[50]\tvalidation_0-rmse:0.319988\n","[51]\tvalidation_0-rmse:0.319966\n","[52]\tvalidation_0-rmse:0.319923\n","[53]\tvalidation_0-rmse:0.319908\n","[54]\tvalidation_0-rmse:0.319887\n","[55]\tvalidation_0-rmse:0.31985\n","[56]\tvalidation_0-rmse:0.319828\n","[57]\tvalidation_0-rmse:0.31977\n","[58]\tvalidation_0-rmse:0.319701\n","[59]\tvalidation_0-rmse:0.319738\n","[60]\tvalidation_0-rmse:0.319695\n","[61]\tvalidation_0-rmse:0.319684\n","[62]\tvalidation_0-rmse:0.319681\n","[63]\tvalidation_0-rmse:0.319673\n","[64]\tvalidation_0-rmse:0.3197\n","[65]\tvalidation_0-rmse:0.319695\n","Stopping. Best iteration:\n","[63]\tvalidation_0-rmse:0.319673\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"8HmynWmsBMXh"},"execution_count":null,"outputs":[]}]}