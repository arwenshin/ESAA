{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6.XGBoost(eXtra Gradient Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##파이썬 래퍼 XGBoost 적용 - 위스콘신 유방암 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\arwen\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_breast_cancer()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = dataset.data\n",
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label = dataset.target\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.DataFrame(data=X_features, columns = dataset.feature_names)\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종양의 크기와 모양에 관련된 많은 속성이 숫자형 값으로 되어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df['target']=y_label\n",
    "y_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃 레이블 값의 종류는 악성인 'malignant' 가 0값으로, 양성인 'benign'이 1값으로 되어 있다.<br>\n",
    "레이블 값의 분포를 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cancer_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1값인 양성 benign이 357개, 0값인 악성 malignant가 212개로 구성되어 있다.<br>\n",
    "전체 데이터 세트 중 80%를 학습용으로, 20%를 테스트용으로 분할하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "#전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features,y_label, test_size = 0.2, random_state=156)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습용과 테스트용 데이터 세트를 위해 별도의 객체인 DMatrix를 생성한다.<br>\n",
    "주요 입력 파라미터<br>\n",
    "data는 피처 데이터 세트이며, label은 분류의 경우에는 레이블 데이터 세트, 회귀의 경우는 숫자형인 종속값 데이터 세트이다.<br>\n",
    "넘파이 형태의 학습 데이터 세트와 테스트 데이터 세트를 DMatrix로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X_train,label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label =y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost를 이용해 학습을 수행하기 전에 먼저 XGBoost의 하이퍼 파라미터를 설정한다. <br>\n",
    "XGBoost의 하이퍼 파라미터는 주로 딕셔너리 형태로 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={ 'max_depth':3, 'eta':0.1, 'objective':'binary:logistic','eval_metric':'logloss','early_stoppings':100}\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬 래퍼 XGBoost는 하이퍼 파라미터는 xgboost 모듈의 train() 함수에 파라미터로 전달한다.<br>\n",
    "조기 중단은 xgboost의 train() 함수에 early_stopping_rounds 파라미터를 입력하여 설정한다. 여기서는 조기 중단 할 수 있는 최소 반복 횟수를 100으로 설정하겠다. <br>\n",
    "early_stopping_rounds 파라미터를 설정해 조기 중단을 수행하기 위해서는 반드시 eval_set 과 eval_metric이 함께 설정되어야 한다. Xgboost는 반복마다 eval_set 으로 지정된 데이터 세트에서 eval_metric의 지정된 평가 지표로 예측 오류를 측정한다.<br>\n",
    "eval_set : 성능 평가를 수행할 평가용 데이터 세트를 설정<br>\n",
    "eval_metric : 평가 세트에 적용할 성능 평가 방법. 분류일 경우 주로 'error'(분류 오류),'logloss'를 적용<br>\n",
    "반복 시마다 evals 에 표시된 데이터 세트에 대해 평가 지표 결과가 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:02:33] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { early_stoppings } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.60969\teval-logloss:0.61352\n",
      "[1]\ttrain-logloss:0.54080\teval-logloss:0.54784\n",
      "[2]\ttrain-logloss:0.48375\teval-logloss:0.49425\n",
      "[3]\ttrain-logloss:0.43446\teval-logloss:0.44799\n",
      "[4]\ttrain-logloss:0.39055\teval-logloss:0.40911\n",
      "[5]\ttrain-logloss:0.35414\teval-logloss:0.37498\n",
      "[6]\ttrain-logloss:0.32122\teval-logloss:0.34571\n",
      "[7]\ttrain-logloss:0.29259\teval-logloss:0.32053\n",
      "[8]\ttrain-logloss:0.26747\teval-logloss:0.29721\n",
      "[9]\ttrain-logloss:0.24515\teval-logloss:0.27799\n",
      "[10]\ttrain-logloss:0.22569\teval-logloss:0.26030\n",
      "[11]\ttrain-logloss:0.20794\teval-logloss:0.24604\n",
      "[12]\ttrain-logloss:0.19218\teval-logloss:0.23156\n",
      "[13]\ttrain-logloss:0.17792\teval-logloss:0.22005\n",
      "[14]\ttrain-logloss:0.16522\teval-logloss:0.20857\n",
      "[15]\ttrain-logloss:0.15362\teval-logloss:0.19999\n",
      "[16]\ttrain-logloss:0.14333\teval-logloss:0.19012\n",
      "[17]\ttrain-logloss:0.13398\teval-logloss:0.18182\n",
      "[18]\ttrain-logloss:0.12560\teval-logloss:0.17473\n",
      "[19]\ttrain-logloss:0.11729\teval-logloss:0.16766\n",
      "[20]\ttrain-logloss:0.10969\teval-logloss:0.15820\n",
      "[21]\ttrain-logloss:0.10297\teval-logloss:0.15473\n",
      "[22]\ttrain-logloss:0.09707\teval-logloss:0.14895\n",
      "[23]\ttrain-logloss:0.09143\teval-logloss:0.14331\n",
      "[24]\ttrain-logloss:0.08633\teval-logloss:0.13634\n",
      "[25]\ttrain-logloss:0.08131\teval-logloss:0.13278\n",
      "[26]\ttrain-logloss:0.07686\teval-logloss:0.12791\n",
      "[27]\ttrain-logloss:0.07284\teval-logloss:0.12526\n",
      "[28]\ttrain-logloss:0.06925\teval-logloss:0.11998\n",
      "[29]\ttrain-logloss:0.06555\teval-logloss:0.11641\n",
      "[30]\ttrain-logloss:0.06241\teval-logloss:0.11450\n",
      "[31]\ttrain-logloss:0.05959\teval-logloss:0.11257\n",
      "[32]\ttrain-logloss:0.05710\teval-logloss:0.11154\n",
      "[33]\ttrain-logloss:0.05441\teval-logloss:0.10868\n",
      "[34]\ttrain-logloss:0.05204\teval-logloss:0.10668\n",
      "[35]\ttrain-logloss:0.04975\teval-logloss:0.10421\n",
      "[36]\ttrain-logloss:0.04775\teval-logloss:0.10296\n",
      "[37]\ttrain-logloss:0.04585\teval-logloss:0.10058\n",
      "[38]\ttrain-logloss:0.04401\teval-logloss:0.09868\n",
      "[39]\ttrain-logloss:0.04226\teval-logloss:0.09644\n",
      "[40]\ttrain-logloss:0.04065\teval-logloss:0.09587\n",
      "[41]\ttrain-logloss:0.03913\teval-logloss:0.09424\n",
      "[42]\ttrain-logloss:0.03738\teval-logloss:0.09471\n",
      "[43]\ttrain-logloss:0.03611\teval-logloss:0.09427\n",
      "[44]\ttrain-logloss:0.03494\teval-logloss:0.09389\n",
      "[45]\ttrain-logloss:0.03365\teval-logloss:0.09418\n",
      "[46]\ttrain-logloss:0.03253\teval-logloss:0.09402\n",
      "[47]\ttrain-logloss:0.03148\teval-logloss:0.09236\n",
      "[48]\ttrain-logloss:0.03039\teval-logloss:0.09301\n",
      "[49]\ttrain-logloss:0.02947\teval-logloss:0.09127\n",
      "[50]\ttrain-logloss:0.02855\teval-logloss:0.09005\n",
      "[51]\ttrain-logloss:0.02753\teval-logloss:0.08961\n",
      "[52]\ttrain-logloss:0.02655\teval-logloss:0.08958\n",
      "[53]\ttrain-logloss:0.02568\teval-logloss:0.09070\n",
      "[54]\ttrain-logloss:0.02500\teval-logloss:0.08958\n",
      "[55]\ttrain-logloss:0.02430\teval-logloss:0.09036\n",
      "[56]\ttrain-logloss:0.02357\teval-logloss:0.09159\n",
      "[57]\ttrain-logloss:0.02296\teval-logloss:0.09153\n",
      "[58]\ttrain-logloss:0.02249\teval-logloss:0.09199\n",
      "[59]\ttrain-logloss:0.02185\teval-logloss:0.09195\n",
      "[60]\ttrain-logloss:0.02132\teval-logloss:0.09194\n",
      "[61]\ttrain-logloss:0.02079\teval-logloss:0.09146\n",
      "[62]\ttrain-logloss:0.02022\teval-logloss:0.09031\n",
      "[63]\ttrain-logloss:0.01970\teval-logloss:0.08941\n",
      "[64]\ttrain-logloss:0.01918\teval-logloss:0.08972\n",
      "[65]\ttrain-logloss:0.01872\teval-logloss:0.08974\n",
      "[66]\ttrain-logloss:0.01833\teval-logloss:0.08962\n",
      "[67]\ttrain-logloss:0.01787\teval-logloss:0.08873\n",
      "[68]\ttrain-logloss:0.01760\teval-logloss:0.08862\n",
      "[69]\ttrain-logloss:0.01724\teval-logloss:0.08974\n",
      "[70]\ttrain-logloss:0.01688\teval-logloss:0.08998\n",
      "[71]\ttrain-logloss:0.01664\teval-logloss:0.08978\n",
      "[72]\ttrain-logloss:0.01629\teval-logloss:0.08958\n",
      "[73]\ttrain-logloss:0.01598\teval-logloss:0.08953\n",
      "[74]\ttrain-logloss:0.01566\teval-logloss:0.08875\n",
      "[75]\ttrain-logloss:0.01539\teval-logloss:0.08860\n",
      "[76]\ttrain-logloss:0.01515\teval-logloss:0.08812\n",
      "[77]\ttrain-logloss:0.01488\teval-logloss:0.08840\n",
      "[78]\ttrain-logloss:0.01464\teval-logloss:0.08874\n",
      "[79]\ttrain-logloss:0.01449\teval-logloss:0.08815\n",
      "[80]\ttrain-logloss:0.01418\teval-logloss:0.08758\n",
      "[81]\ttrain-logloss:0.01401\teval-logloss:0.08741\n",
      "[82]\ttrain-logloss:0.01377\teval-logloss:0.08849\n",
      "[83]\ttrain-logloss:0.01357\teval-logloss:0.08858\n",
      "[84]\ttrain-logloss:0.01341\teval-logloss:0.08807\n",
      "[85]\ttrain-logloss:0.01325\teval-logloss:0.08764\n",
      "[86]\ttrain-logloss:0.01311\teval-logloss:0.08742\n",
      "[87]\ttrain-logloss:0.01293\teval-logloss:0.08761\n",
      "[88]\ttrain-logloss:0.01271\teval-logloss:0.08707\n",
      "[89]\ttrain-logloss:0.01254\teval-logloss:0.08727\n",
      "[90]\ttrain-logloss:0.01235\teval-logloss:0.08716\n",
      "[91]\ttrain-logloss:0.01223\teval-logloss:0.08696\n",
      "[92]\ttrain-logloss:0.01206\teval-logloss:0.08717\n",
      "[93]\ttrain-logloss:0.01193\teval-logloss:0.08707\n",
      "[94]\ttrain-logloss:0.01182\teval-logloss:0.08659\n",
      "[95]\ttrain-logloss:0.01165\teval-logloss:0.08612\n",
      "[96]\ttrain-logloss:0.01148\teval-logloss:0.08714\n",
      "[97]\ttrain-logloss:0.01136\teval-logloss:0.08677\n",
      "[98]\ttrain-logloss:0.01124\teval-logloss:0.08669\n",
      "[99]\ttrain-logloss:0.01113\teval-logloss:0.08655\n",
      "[100]\ttrain-logloss:0.01100\teval-logloss:0.08650\n",
      "[101]\ttrain-logloss:0.01085\teval-logloss:0.08641\n",
      "[102]\ttrain-logloss:0.01076\teval-logloss:0.08629\n",
      "[103]\ttrain-logloss:0.01064\teval-logloss:0.08626\n",
      "[104]\ttrain-logloss:0.01050\teval-logloss:0.08683\n",
      "[105]\ttrain-logloss:0.01039\teval-logloss:0.08677\n",
      "[106]\ttrain-logloss:0.01030\teval-logloss:0.08732\n",
      "[107]\ttrain-logloss:0.01020\teval-logloss:0.08730\n",
      "[108]\ttrain-logloss:0.01007\teval-logloss:0.08728\n",
      "[109]\ttrain-logloss:0.01000\teval-logloss:0.08730\n",
      "[110]\ttrain-logloss:0.00991\teval-logloss:0.08729\n",
      "[111]\ttrain-logloss:0.00980\teval-logloss:0.08800\n",
      "[112]\ttrain-logloss:0.00971\teval-logloss:0.08794\n",
      "[113]\ttrain-logloss:0.00963\teval-logloss:0.08784\n",
      "[114]\ttrain-logloss:0.00956\teval-logloss:0.08807\n",
      "[115]\ttrain-logloss:0.00948\teval-logloss:0.08765\n",
      "[116]\ttrain-logloss:0.00942\teval-logloss:0.08730\n",
      "[117]\ttrain-logloss:0.00931\teval-logloss:0.08780\n",
      "[118]\ttrain-logloss:0.00923\teval-logloss:0.08775\n",
      "[119]\ttrain-logloss:0.00915\teval-logloss:0.08768\n",
      "[120]\ttrain-logloss:0.00912\teval-logloss:0.08763\n",
      "[121]\ttrain-logloss:0.00902\teval-logloss:0.08757\n",
      "[122]\ttrain-logloss:0.00897\teval-logloss:0.08755\n",
      "[123]\ttrain-logloss:0.00890\teval-logloss:0.08716\n",
      "[124]\ttrain-logloss:0.00884\teval-logloss:0.08767\n",
      "[125]\ttrain-logloss:0.00880\teval-logloss:0.08774\n",
      "[126]\ttrain-logloss:0.00871\teval-logloss:0.08828\n",
      "[127]\ttrain-logloss:0.00864\teval-logloss:0.08831\n",
      "[128]\ttrain-logloss:0.00861\teval-logloss:0.08827\n",
      "[129]\ttrain-logloss:0.00856\teval-logloss:0.08789\n",
      "[130]\ttrain-logloss:0.00846\teval-logloss:0.08886\n",
      "[131]\ttrain-logloss:0.00842\teval-logloss:0.08868\n",
      "[132]\ttrain-logloss:0.00839\teval-logloss:0.08874\n",
      "[133]\ttrain-logloss:0.00830\teval-logloss:0.08922\n",
      "[134]\ttrain-logloss:0.00827\teval-logloss:0.08918\n",
      "[135]\ttrain-logloss:0.00822\teval-logloss:0.08882\n",
      "[136]\ttrain-logloss:0.00816\teval-logloss:0.08851\n",
      "[137]\ttrain-logloss:0.00808\teval-logloss:0.08848\n",
      "[138]\ttrain-logloss:0.00805\teval-logloss:0.08839\n",
      "[139]\ttrain-logloss:0.00797\teval-logloss:0.08915\n",
      "[140]\ttrain-logloss:0.00795\teval-logloss:0.08911\n",
      "[141]\ttrain-logloss:0.00790\teval-logloss:0.08876\n",
      "[142]\ttrain-logloss:0.00787\teval-logloss:0.08868\n",
      "[143]\ttrain-logloss:0.00785\teval-logloss:0.08839\n",
      "[144]\ttrain-logloss:0.00778\teval-logloss:0.08927\n",
      "[145]\ttrain-logloss:0.00775\teval-logloss:0.08924\n",
      "[146]\ttrain-logloss:0.00773\teval-logloss:0.08914\n",
      "[147]\ttrain-logloss:0.00769\teval-logloss:0.08891\n",
      "[148]\ttrain-logloss:0.00762\teval-logloss:0.08942\n",
      "[149]\ttrain-logloss:0.00760\teval-logloss:0.08939\n",
      "[150]\ttrain-logloss:0.00758\teval-logloss:0.08911\n",
      "[151]\ttrain-logloss:0.00752\teval-logloss:0.08873\n",
      "[152]\ttrain-logloss:0.00750\teval-logloss:0.08872\n",
      "[153]\ttrain-logloss:0.00746\teval-logloss:0.08848\n",
      "[154]\ttrain-logloss:0.00741\teval-logloss:0.08847\n",
      "[155]\ttrain-logloss:0.00739\teval-logloss:0.08854\n",
      "[156]\ttrain-logloss:0.00737\teval-logloss:0.08852\n",
      "[157]\ttrain-logloss:0.00734\teval-logloss:0.08855\n",
      "[158]\ttrain-logloss:0.00732\teval-logloss:0.08828\n",
      "[159]\ttrain-logloss:0.00730\teval-logloss:0.08830\n",
      "[160]\ttrain-logloss:0.00728\teval-logloss:0.08828\n",
      "[161]\ttrain-logloss:0.00726\teval-logloss:0.08801\n",
      "[162]\ttrain-logloss:0.00724\teval-logloss:0.08776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\ttrain-logloss:0.00722\teval-logloss:0.08778\n",
      "[164]\ttrain-logloss:0.00720\teval-logloss:0.08778\n",
      "[165]\ttrain-logloss:0.00718\teval-logloss:0.08752\n",
      "[166]\ttrain-logloss:0.00716\teval-logloss:0.08754\n",
      "[167]\ttrain-logloss:0.00714\teval-logloss:0.08764\n",
      "[168]\ttrain-logloss:0.00712\teval-logloss:0.08739\n",
      "[169]\ttrain-logloss:0.00710\teval-logloss:0.08738\n",
      "[170]\ttrain-logloss:0.00708\teval-logloss:0.08730\n",
      "[171]\ttrain-logloss:0.00707\teval-logloss:0.08737\n",
      "[172]\ttrain-logloss:0.00705\teval-logloss:0.08740\n",
      "[173]\ttrain-logloss:0.00703\teval-logloss:0.08739\n",
      "[174]\ttrain-logloss:0.00701\teval-logloss:0.08713\n",
      "[175]\ttrain-logloss:0.00699\teval-logloss:0.08716\n",
      "[176]\ttrain-logloss:0.00697\teval-logloss:0.08696\n",
      "[177]\ttrain-logloss:0.00696\teval-logloss:0.08705\n",
      "[178]\ttrain-logloss:0.00694\teval-logloss:0.08697\n",
      "[179]\ttrain-logloss:0.00692\teval-logloss:0.08697\n",
      "[180]\ttrain-logloss:0.00690\teval-logloss:0.08704\n",
      "[181]\ttrain-logloss:0.00688\teval-logloss:0.08680\n",
      "[182]\ttrain-logloss:0.00687\teval-logloss:0.08683\n",
      "[183]\ttrain-logloss:0.00685\teval-logloss:0.08658\n",
      "[184]\ttrain-logloss:0.00683\teval-logloss:0.08659\n",
      "[185]\ttrain-logloss:0.00681\teval-logloss:0.08661\n",
      "[186]\ttrain-logloss:0.00680\teval-logloss:0.08637\n",
      "[187]\ttrain-logloss:0.00678\teval-logloss:0.08637\n",
      "[188]\ttrain-logloss:0.00676\teval-logloss:0.08630\n",
      "[189]\ttrain-logloss:0.00675\teval-logloss:0.08610\n",
      "[190]\ttrain-logloss:0.00673\teval-logloss:0.08602\n",
      "[191]\ttrain-logloss:0.00671\teval-logloss:0.08605\n",
      "[192]\ttrain-logloss:0.00670\teval-logloss:0.08615\n",
      "[193]\ttrain-logloss:0.00668\teval-logloss:0.08592\n",
      "[194]\ttrain-logloss:0.00667\teval-logloss:0.08592\n",
      "[195]\ttrain-logloss:0.00665\teval-logloss:0.08598\n",
      "[196]\ttrain-logloss:0.00663\teval-logloss:0.08601\n",
      "[197]\ttrain-logloss:0.00662\teval-logloss:0.08592\n",
      "[198]\ttrain-logloss:0.00660\teval-logloss:0.08585\n",
      "[199]\ttrain-logloss:0.00659\teval-logloss:0.08587\n",
      "[200]\ttrain-logloss:0.00657\teval-logloss:0.08589\n",
      "[201]\ttrain-logloss:0.00656\teval-logloss:0.08595\n",
      "[202]\ttrain-logloss:0.00654\teval-logloss:0.08573\n",
      "[203]\ttrain-logloss:0.00653\teval-logloss:0.08573\n",
      "[204]\ttrain-logloss:0.00651\teval-logloss:0.08575\n",
      "[205]\ttrain-logloss:0.00650\teval-logloss:0.08582\n",
      "[206]\ttrain-logloss:0.00648\teval-logloss:0.08584\n",
      "[207]\ttrain-logloss:0.00647\teval-logloss:0.08578\n",
      "[208]\ttrain-logloss:0.00645\teval-logloss:0.08569\n",
      "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
      "[210]\ttrain-logloss:0.00643\teval-logloss:0.08581\n",
      "[211]\ttrain-logloss:0.00641\teval-logloss:0.08559\n",
      "[212]\ttrain-logloss:0.00640\teval-logloss:0.08580\n",
      "[213]\ttrain-logloss:0.00639\teval-logloss:0.08581\n",
      "[214]\ttrain-logloss:0.00637\teval-logloss:0.08574\n",
      "[215]\ttrain-logloss:0.00636\teval-logloss:0.08566\n",
      "[216]\ttrain-logloss:0.00634\teval-logloss:0.08584\n",
      "[217]\ttrain-logloss:0.00633\teval-logloss:0.08563\n",
      "[218]\ttrain-logloss:0.00632\teval-logloss:0.08573\n",
      "[219]\ttrain-logloss:0.00631\teval-logloss:0.08578\n",
      "[220]\ttrain-logloss:0.00629\teval-logloss:0.08579\n",
      "[221]\ttrain-logloss:0.00628\teval-logloss:0.08582\n",
      "[222]\ttrain-logloss:0.00627\teval-logloss:0.08576\n",
      "[223]\ttrain-logloss:0.00626\teval-logloss:0.08567\n",
      "[224]\ttrain-logloss:0.00624\teval-logloss:0.08586\n",
      "[225]\ttrain-logloss:0.00623\teval-logloss:0.08587\n",
      "[226]\ttrain-logloss:0.00622\teval-logloss:0.08593\n",
      "[227]\ttrain-logloss:0.00621\teval-logloss:0.08595\n",
      "[228]\ttrain-logloss:0.00619\teval-logloss:0.08587\n",
      "[229]\ttrain-logloss:0.00618\teval-logloss:0.08606\n",
      "[230]\ttrain-logloss:0.00617\teval-logloss:0.08600\n",
      "[231]\ttrain-logloss:0.00616\teval-logloss:0.08592\n",
      "[232]\ttrain-logloss:0.00615\teval-logloss:0.08610\n",
      "[233]\ttrain-logloss:0.00613\teval-logloss:0.08611\n",
      "[234]\ttrain-logloss:0.00612\teval-logloss:0.08617\n",
      "[235]\ttrain-logloss:0.00611\teval-logloss:0.08626\n",
      "[236]\ttrain-logloss:0.00610\teval-logloss:0.08629\n",
      "[237]\ttrain-logloss:0.00609\teval-logloss:0.08622\n",
      "[238]\ttrain-logloss:0.00608\teval-logloss:0.08639\n",
      "[239]\ttrain-logloss:0.00607\teval-logloss:0.08634\n",
      "[240]\ttrain-logloss:0.00606\teval-logloss:0.08618\n",
      "[241]\ttrain-logloss:0.00605\teval-logloss:0.08619\n",
      "[242]\ttrain-logloss:0.00604\teval-logloss:0.08625\n",
      "[243]\ttrain-logloss:0.00602\teval-logloss:0.08626\n",
      "[244]\ttrain-logloss:0.00601\teval-logloss:0.08629\n",
      "[245]\ttrain-logloss:0.00600\teval-logloss:0.08622\n",
      "[246]\ttrain-logloss:0.00599\teval-logloss:0.08640\n",
      "[247]\ttrain-logloss:0.00598\teval-logloss:0.08635\n",
      "[248]\ttrain-logloss:0.00597\teval-logloss:0.08628\n",
      "[249]\ttrain-logloss:0.00596\teval-logloss:0.08645\n",
      "[250]\ttrain-logloss:0.00595\teval-logloss:0.08629\n",
      "[251]\ttrain-logloss:0.00594\teval-logloss:0.08631\n",
      "[252]\ttrain-logloss:0.00593\teval-logloss:0.08636\n",
      "[253]\ttrain-logloss:0.00592\teval-logloss:0.08639\n",
      "[254]\ttrain-logloss:0.00591\teval-logloss:0.08649\n",
      "[255]\ttrain-logloss:0.00590\teval-logloss:0.08644\n",
      "[256]\ttrain-logloss:0.00589\teval-logloss:0.08629\n",
      "[257]\ttrain-logloss:0.00588\teval-logloss:0.08646\n",
      "[258]\ttrain-logloss:0.00587\teval-logloss:0.08639\n",
      "[259]\ttrain-logloss:0.00586\teval-logloss:0.08644\n",
      "[260]\ttrain-logloss:0.00585\teval-logloss:0.08646\n",
      "[261]\ttrain-logloss:0.00585\teval-logloss:0.08649\n",
      "[262]\ttrain-logloss:0.00584\teval-logloss:0.08644\n",
      "[263]\ttrain-logloss:0.00583\teval-logloss:0.08647\n",
      "[264]\ttrain-logloss:0.00582\teval-logloss:0.08632\n",
      "[265]\ttrain-logloss:0.00581\teval-logloss:0.08649\n",
      "[266]\ttrain-logloss:0.00580\teval-logloss:0.08654\n",
      "[267]\ttrain-logloss:0.00579\teval-logloss:0.08647\n",
      "[268]\ttrain-logloss:0.00578\teval-logloss:0.08650\n",
      "[269]\ttrain-logloss:0.00577\teval-logloss:0.08652\n",
      "[270]\ttrain-logloss:0.00576\teval-logloss:0.08669\n",
      "[271]\ttrain-logloss:0.00575\teval-logloss:0.08674\n",
      "[272]\ttrain-logloss:0.00575\teval-logloss:0.08683\n",
      "[273]\ttrain-logloss:0.00574\teval-logloss:0.08668\n",
      "[274]\ttrain-logloss:0.00573\teval-logloss:0.08664\n",
      "[275]\ttrain-logloss:0.00572\teval-logloss:0.08650\n",
      "[276]\ttrain-logloss:0.00571\teval-logloss:0.08636\n",
      "[277]\ttrain-logloss:0.00570\teval-logloss:0.08652\n",
      "[278]\ttrain-logloss:0.00570\teval-logloss:0.08657\n",
      "[279]\ttrain-logloss:0.00569\teval-logloss:0.08659\n",
      "[280]\ttrain-logloss:0.00568\teval-logloss:0.08668\n",
      "[281]\ttrain-logloss:0.00567\teval-logloss:0.08664\n",
      "[282]\ttrain-logloss:0.00566\teval-logloss:0.08650\n",
      "[283]\ttrain-logloss:0.00566\teval-logloss:0.08636\n",
      "[284]\ttrain-logloss:0.00565\teval-logloss:0.08640\n",
      "[285]\ttrain-logloss:0.00564\teval-logloss:0.08643\n",
      "[286]\ttrain-logloss:0.00563\teval-logloss:0.08646\n",
      "[287]\ttrain-logloss:0.00562\teval-logloss:0.08650\n",
      "[288]\ttrain-logloss:0.00562\teval-logloss:0.08637\n",
      "[289]\ttrain-logloss:0.00561\teval-logloss:0.08646\n",
      "[290]\ttrain-logloss:0.00560\teval-logloss:0.08645\n",
      "[291]\ttrain-logloss:0.00559\teval-logloss:0.08632\n",
      "[292]\ttrain-logloss:0.00558\teval-logloss:0.08628\n",
      "[293]\ttrain-logloss:0.00558\teval-logloss:0.08615\n",
      "[294]\ttrain-logloss:0.00557\teval-logloss:0.08620\n",
      "[295]\ttrain-logloss:0.00556\teval-logloss:0.08622\n",
      "[296]\ttrain-logloss:0.00556\teval-logloss:0.08631\n",
      "[297]\ttrain-logloss:0.00555\teval-logloss:0.08618\n",
      "[298]\ttrain-logloss:0.00554\teval-logloss:0.08626\n",
      "[299]\ttrain-logloss:0.00553\teval-logloss:0.08613\n",
      "[300]\ttrain-logloss:0.00553\teval-logloss:0.08618\n",
      "[301]\ttrain-logloss:0.00552\teval-logloss:0.08605\n",
      "[302]\ttrain-logloss:0.00551\teval-logloss:0.08602\n",
      "[303]\ttrain-logloss:0.00551\teval-logloss:0.08610\n",
      "[304]\ttrain-logloss:0.00550\teval-logloss:0.08598\n",
      "[305]\ttrain-logloss:0.00549\teval-logloss:0.08606\n",
      "[306]\ttrain-logloss:0.00548\teval-logloss:0.08597\n",
      "[307]\ttrain-logloss:0.00548\teval-logloss:0.08600\n",
      "[308]\ttrain-logloss:0.00547\teval-logloss:0.08600\n",
      "[309]\ttrain-logloss:0.00546\teval-logloss:0.08588\n",
      "[310]\ttrain-logloss:0.00546\teval-logloss:0.08592\n"
     ]
    }
   ],
   "source": [
    "#train 데이터 세트는 'train',evaluation(test) 데이터 세트는 'eval'로 명기합니다.\n",
    "wlist = [(dtrain,'train'),(dtest,'eval')]\n",
    "#하이퍼 파라미터와 early stopping 파라미터는 train() 함수의 파라미터로 전달\n",
    "xbg_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = num_rounds, early_stopping_rounds=100, evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-69e6c0ef94fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost를 이용해 모델의 학습이 완료됐으면 이를 이용해 테스트 데이터 세트에 예측을 수행해 보겠다. 파이썬 래퍼 XGBoost는 XGBoost는 train() 함수를 호출해 학습이 완료된 모델 객체를 반환하게 되는데, 이 모델 객체는 예측을 위해 predict() 메서드를 이용한다. 한 가지 유의할 점은 사이킷런의 predict() 메서드는 예측 결과 클래스 값(0 or 1) 을 반환하는 데 반해 xgboost의 predict()는 예측 결괏값이 아닌 예측 결과를 추정할 수 있는 확률 값을 반환한다는 점이다. 본 예제는 암이 악성인지, 양성인지를 판단하는 이진 분류이므로 예측 확률이 0.5보다 크면 1, 그렇지 않으면 0으로 예측 값을 결정하는 로직을 추가하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-563f8cc1911d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict() 수행 결괏값을 10개만 표시, 예측 확률값으로 표시됨'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict() 수행 결괏값을 10개만 표시, 예측 확률값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test,pred=None,pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1 =f1_score(y_test,pred)\n",
    "    roc_auc = roc_auc_score(y_test,pred_proba)\n",
    "    print(\"오차 행렬\")\n",
    "    print(confusion)\n",
    "    print(\"정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}, AUC={4:.4f}\".format(accuracy,precision,recall,f1,roc_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
