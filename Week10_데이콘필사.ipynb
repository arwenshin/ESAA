{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week10_데이콘필사.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1A9WXAYRn4EJIftYvBboIKLNmYeOJsGcg","authorship_tag":"ABX9TyOz6ArAMU1mNdZu5RewhMjf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/ESAA(22-1)/Week9/소설 작가 분류 AI 경진대회/train.csv') "],"metadata":{"id":"h8SoRaEKWzO1","executionInfo":{"status":"ok","timestamp":1652092011881,"user_tz":-540,"elapsed":1045,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def text2sequence(train_text, max_len=100):\n","    \n","    tokenizer = Tokenizer() #keras의 vectorizing 함수 호출\n","    tokenizer.fit_on_texts(train_text) #train 문장에 fit\n","    train_X_seq = tokenizer.texts_to_sequences(train_text) #각 토큰들에 정수 부여\n","    vocab_size = len(tokenizer.word_index) + 1 #모델에 알려줄 vocabulary의 크기 계산\n","    print('vocab_size : ', vocab_size)\n","    X_train = pad_sequences(train_X_seq, maxlen = max_len) #설정한 문장의 최대 길이만큼 padding\n","    \n","    return X_train, vocab_size, tokenizer\n","\n","train_X, vocab_size, vectorizer = text2sequence(train['text'], max_len = 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkGGRDMWWn5j","executionInfo":{"status":"ok","timestamp":1652092019016,"user_tz":-540,"elapsed":5570,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"b0aa58ea-0d82-4499-9d2c-b22d4053745f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab_size :  42331\n"]}]},{"cell_type":"markdown","source":["#1. keras Embedding Layer"],"metadata":{"id":"GnyLgdgWLKE5"}},{"cell_type":"code","source":["max_len = 100\n","vocabulary = vectorizer.word_index"],"metadata":{"id":"BAF8PlT9UwrP","executionInfo":{"status":"ok","timestamp":1652092025361,"user_tz":-540,"elapsed":328,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"id":"1do-ySJVK_fS","executionInfo":{"status":"ok","timestamp":1652092030927,"user_tz":-540,"elapsed":322,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"outputs":[],"source":["from keras.models import Sequential\n","from tensorflow.keras.layers import Embedding\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, 128, input_length = max_len))"]},{"cell_type":"markdown","source":["#2. "],"metadata":{"id":"JQcHcNW4LTMO"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/ESAA(22-1)/Week10')"],"metadata":{"id":"Z7gqpIXJTzlW","executionInfo":{"status":"ok","timestamp":1652092035352,"user_tz":-540,"elapsed":257,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import gensim\n","word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary = True)"],"metadata":{"id":"SPbiCgY7LSyG","executionInfo":{"status":"ok","timestamp":1652092179915,"user_tz":-540,"elapsed":143417,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","embedding_matrix = np.zeros((vocab_size,300)) #300차원의 임베딩 매트릭스 생성\n","\n","for index,word in enumerate(vocabulary):  #vocabulary에 있는 토큰들을 하나씩 넘겨줍니다.\n","    if word in word2vec: #넘겨 받은 토큰이 word2vect 에 존재하면(이미 훈련이 된 토큰이라는 뜻)\n","        embedding_vector = word2vec[word]  #해당 토큰에 해당하는 vector를 불러오고\n","        embedding_matrix[index] = embedding_vector  #해당 위치의 embedding_matrix에 저장한다.\n","    else:\n","        print('word2vect에 없는 단어입니다.')\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2qUyFcDNU-C","executionInfo":{"status":"ok","timestamp":1652092449692,"user_tz":-540,"elapsed":245,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"afc6251d-0eeb-4e33-95a0-cafb49e51bb3"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["word2vect에 없는 단어입니다.\n"]}]},{"cell_type":"markdown","source":["#3. glove"],"metadata":{"id":"axD-ZrrONB1m"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/ESAA(22-1)/Week10/word-embeddings/word-embeddings')"],"metadata":{"id":"Vq5mUJNFQ6ZK","executionInfo":{"status":"ok","timestamp":1652092219415,"user_tz":-540,"elapsed":278,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["2. # load the whole embedding into memory\n","import numpy as np\n","glove = dict()\n","f = open('/content/drive/MyDrive/ESAA(22-1)/Week10/word-embeddings/word-embeddings/glove/glove.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    vector = np.asarray(values[1:], dtype='float32')\n","    glove[word] = vector\n","f.close()"],"metadata":{"id":"YtfAHrslNDh5","executionInfo":{"status":"ok","timestamp":1652091794727,"user_tz":-540,"elapsed":10897,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["vocabulary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBWsAM7aX4Ld","executionInfo":{"status":"ok","timestamp":1652092295673,"user_tz":-540,"elapsed":272,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"f9cb6c97-fd7e-456f-c7f4-0f8694400518"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'the': 1,\n"," 'and': 2,\n"," 'to': 3,\n"," 'of': 4,\n"," 'a': 5,\n"," 'i': 6,\n"," 'in': 7,\n"," 'odin': 8,\n"," '”': 9,\n"," 'he': 10,\n"," 'was': 11,\n"," 'it': 12,\n"," 'you': 13,\n"," 'that': 14,\n"," 'his': 15,\n"," 'with': 16,\n"," 'had': 17,\n"," 'for': 18,\n"," 'as': 19,\n"," 'her': 20,\n"," 'at': 21,\n"," 'not': 22,\n"," 'my': 23,\n"," 'is': 24,\n"," 'but': 25,\n"," 'have': 26,\n"," 'be': 27,\n"," 'she': 28,\n"," 'me': 29,\n"," 'him': 30,\n"," 'said': 31,\n"," 'on': 32,\n"," 'all': 33,\n"," 'so': 34,\n"," 'this': 35,\n"," 'from': 36,\n"," 'by': 37,\n"," 'which': 38,\n"," 'were': 39,\n"," '’': 40,\n"," 'there': 41,\n"," 'no': 42,\n"," 'one': 43,\n"," 'what': 44,\n"," 'been': 45,\n"," 'would': 46,\n"," 'we': 47,\n"," 'they': 48,\n"," 'are': 49,\n"," 'your': 50,\n"," 'if': 51,\n"," 'an': 52,\n"," 'very': 53,\n"," 'mr': 54,\n"," 'could': 55,\n"," 'do': 56,\n"," 'out': 57,\n"," 'will': 58,\n"," 'when': 59,\n"," 'up': 60,\n"," 'or': 61,\n"," 'upon': 62,\n"," 'them': 63,\n"," 'more': 64,\n"," 'man': 65,\n"," 'now': 66,\n"," 'who': 67,\n"," 'some': 68,\n"," \"'\": 69,\n"," 'am': 70,\n"," 'know': 71,\n"," '“i': 72,\n"," 'then': 73,\n"," 'into': 74,\n"," 'about': 75,\n"," 'time': 76,\n"," 'little': 77,\n"," 'their': 78,\n"," 'did': 79,\n"," 'only': 80,\n"," 'see': 81,\n"," 'like': 82,\n"," 'before': 83,\n"," 'should': 84,\n"," 'come': 85,\n"," 'must': 86,\n"," 'such': 87,\n"," 'any': 88,\n"," 'than': 89,\n"," 'down': 90,\n"," 'how': 91,\n"," 'has': 92,\n"," 'much': 93,\n"," 'say': 94,\n"," 'good': 95,\n"," 'here': 96,\n"," 'can': 97,\n"," 'well': 98,\n"," 'us': 99,\n"," 'think': 100,\n"," 'again': 101,\n"," 'our': 102,\n"," 'never': 103,\n"," 'too': 104,\n"," 'cried': 105,\n"," 'may': 106,\n"," 'two': 107,\n"," 'over': 108,\n"," 'sir': 109,\n"," 'other': 110,\n"," 'go': 111,\n"," 'after': 112,\n"," 'made': 113,\n"," 'himself': 114,\n"," 'though': 115,\n"," 'old': 116,\n"," 'own': 117,\n"," 'came': 118,\n"," 'great': 119,\n"," 'nothing': 120,\n"," 'last': 121,\n"," 'way': 122,\n"," 'thought': 123,\n"," 'might': 124,\n"," 'hand': 125,\n"," 'first': 126,\n"," 'back': 127,\n"," 'shall': 128,\n"," 'long': 129,\n"," 'even': 130,\n"," 'face': 131,\n"," 'day': 132,\n"," 'away': 133,\n"," 'room': 134,\n"," 'mrs': 135,\n"," 'house': 136,\n"," 'without': 137,\n"," 'every': 138,\n"," 'once': 139,\n"," 'still': 140,\n"," 'eyes': 141,\n"," 'miss': 142,\n"," 'looked': 143,\n"," 'asked': 144,\n"," 'being': 145,\n"," 'went': 146,\n"," 'where': 147,\n"," 'these': 148,\n"," 'make': 149,\n"," 'most': 150,\n"," 'tell': 151,\n"," 'young': 152,\n"," 'just': 153,\n"," 'head': 154,\n"," 'something': 155,\n"," 'off': 156,\n"," 'take': 157,\n"," 'quite': 158,\n"," 'myself': 159,\n"," '“you': 160,\n"," 'night': 161,\n"," 'yet': 162,\n"," 'look': 163,\n"," 'same': 164,\n"," 'door': 165,\n"," 'why': 166,\n"," 'dear': 167,\n"," 'another': 168,\n"," 'ever': 169,\n"," 'life': 170,\n"," 'saw': 171,\n"," 'don’t': 172,\n"," 'mind': 173,\n"," 'its': 174,\n"," 'heard': 175,\n"," 'always': 176,\n"," 'moment': 177,\n"," 'took': 178,\n"," 'put': 179,\n"," \"odin's\": 180,\n"," '“and': 181,\n"," 'seemed': 182,\n"," 'three': 183,\n"," 'while': 184,\n"," 'left': 185,\n"," 'prince': 186,\n"," 'through': 187,\n"," 'give': 188,\n"," 'looking': 189,\n"," 'began': 190,\n"," 'right': 191,\n"," 'let': 192,\n"," 'better': 193,\n"," 'going': 194,\n"," 'heart': 195,\n"," 'done': 196,\n"," 'get': 197,\n"," 'many': 198,\n"," 'thing': 199,\n"," 'place': 200,\n"," 'hands': 201,\n"," 'odin’s': 202,\n"," 'word': 203,\n"," 'perhaps': 204,\n"," 'soon': 205,\n"," 'suddenly': 206,\n"," 'replied': 207,\n"," 'told': 208,\n"," 'found': 209,\n"," 'enough': 210,\n"," 'father': 211,\n"," 'got': 212,\n"," 'lady': 213,\n"," 'turned': 214,\n"," 'those': 215,\n"," 'seen': 216,\n"," 'knew': 217,\n"," 'sure': 218,\n"," 'believe': 219,\n"," 'friend': 220,\n"," 'round': 221,\n"," 'side': 222,\n"," 'indeed': 223,\n"," 'returned': 224,\n"," 'course': 225,\n"," 'half': 226,\n"," 'morning': 227,\n"," 'people': 228,\n"," 'herself': 229,\n"," 'anything': 230,\n"," 'men': 231,\n"," 'love': 232,\n"," 'voice': 233,\n"," 'under': 234,\n"," 'both': 235,\n"," 'woman': 236,\n"," '“but': 237,\n"," 'whole': 238,\n"," 'words': 239,\n"," '“what': 240,\n"," 'sat': 241,\n"," 'far': 242,\n"," 'almost': 243,\n"," 'however': 244,\n"," 'name': 245,\n"," 'want': 246,\n"," 'home': 247,\n"," 'felt': 248,\n"," '“it': 249,\n"," 'find': 250,\n"," 'mother': 251,\n"," 'rather': 252,\n"," 'whom': 253,\n"," 'hear': 254,\n"," 'really': 255,\n"," 'having': 256,\n"," 'against': 257,\n"," 'end': 258,\n"," 'stood': 259,\n"," 'yourself': 260,\n"," 'it’s': 261,\n"," 'answered': 262,\n"," 'matter': 263,\n"," 'poor': 264,\n"," 'between': 265,\n"," 'speak': 266,\n"," 'understand': 267,\n"," 'gone': 268,\n"," 'cannot': 269,\n"," 'money': 270,\n"," '‘i': 271,\n"," 'brought': 272,\n"," 'years': 273,\n"," 'part': 274,\n"," 'because': 275,\n"," 'gave': 276,\n"," 'hope': 277,\n"," 'few': 278,\n"," 'together': 279,\n"," 'light': 280,\n"," 'among': 281,\n"," 'mean': 282,\n"," 'doctor': 283,\n"," 'table': 284,\n"," 'set': 285,\n"," 'open': 286,\n"," 'case': 287,\n"," 'boy': 288,\n"," 'evening': 289,\n"," 'already': 290,\n"," 'things': 291,\n"," 'new': 292,\n"," 'since': 293,\n"," 'ask': 294,\n"," 'brother': 295,\n"," 'taken': 296,\n"," 'leave': 297,\n"," 'lay': 298,\n"," 'hour': 299,\n"," \"don't\": 300,\n"," 'letter': 301,\n"," 'next': 302,\n"," 'passed': 303,\n"," '“well': 304,\n"," 'gentleman': 305,\n"," 'business': 306,\n"," '“yes': 307,\n"," 'world': 308,\n"," 'does': 309,\n"," 'lord': 310,\n"," 'least': 311,\n"," 'ye': 312,\n"," 'yes': 313,\n"," 'family': 314,\n"," 'general': 315,\n"," 'question': 316,\n"," 'days': 317,\n"," 'each': 318,\n"," 'doubt': 319,\n"," '“no': 320,\n"," 'answer': 321,\n"," 'idea': 322,\n"," 'wish': 323,\n"," 'sister': 324,\n"," 'behind': 325,\n"," 'wife': 326,\n"," 'everything': 327,\n"," '“the': 328,\n"," 'towards': 329,\n"," 'best': 330,\n"," 'oh': 331,\n"," 'help': 332,\n"," 'else': 333,\n"," 'alone': 334,\n"," 'remember': 335,\n"," 'air': 336,\n"," 'master': 337,\n"," 'sort': 338,\n"," 'point': 339,\n"," 'coming': 340,\n"," 'nor': 341,\n"," 'small': 342,\n"," 'keep': 343,\n"," 'until': 344,\n"," 'god': 345,\n"," 'suppose': 346,\n"," 'certainly': 347,\n"," 'whether': 348,\n"," 'manner': 349,\n"," 'strange': 350,\n"," 'read': 351,\n"," 'present': 352,\n"," 'short': 353,\n"," '“oh': 354,\n"," 'added': 355,\n"," 'fellow': 356,\n"," 'work': 357,\n"," 'black': 358,\n"," '“that': 359,\n"," 'five': 360,\n"," 'called': 361,\n"," 'says': 362,\n"," 'fire': 363,\n"," 'less': 364,\n"," 'true': 365,\n"," 'town': 366,\n"," 'kind': 367,\n"," 'window': 368,\n"," 'till': 369,\n"," 'afraid': 370,\n"," 'street': 371,\n"," 'that’s': 372,\n"," 'talk': 373,\n"," 'happy': 374,\n"," 'often': 375,\n"," 'girl': 376,\n"," 'aunt': 377,\n"," 'walked': 378,\n"," 'known': 379,\n"," 'spoke': 380,\n"," 'child': 381,\n"," 'observed': 382,\n"," 'dark': 383,\n"," 'within': 384,\n"," 'chair': 385,\n"," 'captain': 386,\n"," 'full': 387,\n"," 'fact': 388,\n"," 'dead': 389,\n"," 'friends': 390,\n"," \"it's\": 391,\n"," 'ill': 392,\n"," 'either': 393,\n"," 'bed': 394,\n"," 'possible': 395,\n"," 'reason': 396,\n"," 'fell': 397,\n"," 'hardly': 398,\n"," 'near': 399,\n"," 'feel': 400,\n"," 'given': 401,\n"," 'used': 402,\n"," 'call': 403,\n"," 'four': 404,\n"," 'death': 405,\n"," 'times': 406,\n"," '“he': 407,\n"," 'certain': 408,\n"," 'ran': 409,\n"," 'white': 410,\n"," 'ready': 411,\n"," 'kept': 412,\n"," 'smile': 413,\n"," 'high': 414,\n"," 'person': 415,\n"," 'struck': 416,\n"," 'silence': 417,\n"," 'clear': 418,\n"," 'rest': 419,\n"," 'others': 420,\n"," 'country': 421,\n"," 'taking': 422,\n"," 'hard': 423,\n"," 'feet': 424,\n"," '“why': 425,\n"," 'lost': 426,\n"," 'appeared': 427,\n"," 'sometimes': 428,\n"," 'thousand': 429,\n"," 'also': 430,\n"," 'strong': 431,\n"," 'turn': 432,\n"," 'mine': 433,\n"," 'large': 434,\n"," 'second': 435,\n"," 'glad': 436,\n"," 'i’ll': 437,\n"," 'pleasure': 438,\n"," 'hundred': 439,\n"," 'making': 440,\n"," 'means': 441,\n"," 'wanted': 442,\n"," 'feeling': 443,\n"," 'opened': 444,\n"," 'afterwards': 445,\n"," 'subject': 446,\n"," 'along': 447,\n"," 'followed': 448,\n"," 'continued': 449,\n"," 'doing': 450,\n"," 'deal': 451,\n"," 'held': 452,\n"," 'water': 453,\n"," 'ten': 454,\n"," 'london': 455,\n"," 'above': 456,\n"," \"'i\": 457,\n"," 'sitting': 458,\n"," 'saying': 459,\n"," 'met': 460,\n"," 'hold': 461,\n"," 'eye': 462,\n"," 'state': 463,\n"," 'fear': 464,\n"," 'across': 465,\n"," 'bring': 466,\n"," 'need': 467,\n"," 'forward': 468,\n"," '“if': 469,\n"," 'cold': 470,\n"," 'truth': 471,\n"," 'corner': 472,\n"," 'thinking': 473,\n"," 'company': 474,\n"," 'care': 475,\n"," 'show': 476,\n"," 'low': 477,\n"," 'silent': 478,\n"," 'walk': 479,\n"," 'pretty': 480,\n"," 'arm': 481,\n"," 'minutes': 482,\n"," 'close': 483,\n"," 'able': 484,\n"," 'run': 485,\n"," 'sent': 486,\n"," 'son': 487,\n"," 'joe': 488,\n"," 'arms': 489,\n"," 'laughed': 490,\n"," 'nature': 491,\n"," 'turning': 492,\n"," 'body': 493,\n"," 'late': 494,\n"," 'past': 495,\n"," 'use': 496,\n"," 'account': 497,\n"," 'interest': 498,\n"," '“odin': 499,\n"," \"that's\": 500,\n"," 'ivan': 501,\n"," '“my': 502,\n"," 'happened': 503,\n"," 'became': 504,\n"," 'gentlemen': 505,\n"," 'ought': 506,\n"," 'story': 507,\n"," 'children': 508,\n"," 'live': 509,\n"," 'instant': 510,\n"," 'return': 511,\n"," 'red': 512,\n"," 'standing': 513,\n"," 'talking': 514,\n"," 'sight': 515,\n"," 'repeated': 516,\n"," 'paper': 517,\n"," 'bad': 518,\n"," 'opinion': 519,\n"," 'twenty': 520,\n"," 'dare': 521,\n"," 'ground': 522,\n"," '“how': 523,\n"," 'blood': 524,\n"," 'whose': 525,\n"," 'feelings': 526,\n"," 'seeing': 527,\n"," 'object': 528,\n"," 'character': 529,\n"," 'sound': 530,\n"," 'laughing': 531,\n"," 'sit': 532,\n"," 'ago': 533,\n"," 'attention': 534,\n"," 'surprise': 535,\n"," 'stopped': 536,\n"," 'tried': 537,\n"," 'simply': 538,\n"," 'visit': 539,\n"," 'therefore': 540,\n"," 'knows': 541,\n"," '‘you': 542,\n"," '“there': 543,\n"," 'minute': 544,\n"," 'different': 545,\n"," 'beyond': 546,\n"," 'drew': 547,\n"," 'party': 548,\n"," 'change': 549,\n"," 'husband': 550,\n"," 'several': 551,\n"," 'please': 552,\n"," 'hair': 553,\n"," 'won’t': 554,\n"," 'year': 555,\n"," 'immediately': 556,\n"," 'deep': 557,\n"," 'conversation': 558,\n"," 'expression': 559,\n"," 'speaking': 560,\n"," 'hours': 561,\n"," 'soul': 562,\n"," 'wonder': 563,\n"," 'secret': 564,\n"," 'laid': 565,\n"," 'sorry': 566,\n"," 'odins': 567,\n"," 'sudden': 568,\n"," 'road': 569,\n"," 'impossible': 570,\n"," 'bear': 571,\n"," '“we': 572,\n"," 'creature': 573,\n"," 'received': 574,\n"," 'can’t': 575,\n"," 'themselves': 576,\n"," 'neither': 577,\n"," 'appearance': 578,\n"," 'note': 579,\n"," 'stand': 580,\n"," 'six': 581,\n"," 'didn’t': 582,\n"," 'longer': 583,\n"," 'none': 584,\n"," 'sense': 585,\n"," 'carried': 586,\n"," 'daughter': 587,\n"," 'lips': 588,\n"," 'carriage': 589,\n"," 'angry': 590,\n"," 'sea': 591,\n"," 'waiting': 592,\n"," 'pass': 593,\n"," 'fine': 594,\n"," 'purpose': 595,\n"," 'married': 596,\n"," 'front': 597,\n"," 'power': 598,\n"," 'honour': 599,\n"," 'seems': 600,\n"," 'entered': 601,\n"," 'tears': 602,\n"," 'i’m': 603,\n"," 'stay': 604,\n"," 'i’ve': 605,\n"," 'led': 606,\n"," 'besides': 607,\n"," 'beside': 608,\n"," 'yesterday': 609,\n"," 'dinner': 610,\n"," 'order': 611,\n"," 'seem': 612,\n"," 'week': 613,\n"," '‘and': 614,\n"," 'forth': 615,\n"," \"i'll\": 616,\n"," 'quiet': 617,\n"," '“a': 618,\n"," 'likely': 619,\n"," 'straight': 620,\n"," 'common': 621,\n"," 'during': 622,\n"," 'perfectly': 623,\n"," 'sake': 624,\n"," 'early': 625,\n"," 'glass': 626,\n"," 'jane': 627,\n"," 'step': 628,\n"," 'later': 629,\n"," 'lying': 630,\n"," 'laugh': 631,\n"," 'morrow': 632,\n"," '“then': 633,\n"," 'wrong': 634,\n"," 'fancy': 635,\n"," 'getting': 636,\n"," 'cut': 637,\n"," 'broke': 638,\n"," 'wall': 639,\n"," 'foot': 640,\n"," 'write': 641,\n"," 'meant': 642,\n"," 'surprised': 643,\n"," '“this': 644,\n"," 'book': 645,\n"," 'showed': 646,\n"," 'wait': 647,\n"," 'reached': 648,\n"," 'thoughts': 649,\n"," 'spirits': 650,\n"," 'acquaintance': 651,\n"," 'broken': 652,\n"," 'usual': 653,\n"," 'wind': 654,\n"," 'companion': 655,\n"," 'garden': 656,\n"," 'itself': 657,\n"," 'pale': 658,\n"," 'meet': 659,\n"," 'police': 660,\n"," 'comes': 661,\n"," 'expected': 662,\n"," 'spite': 663,\n"," 'dr': 664,\n"," 'become': 665,\n"," 'imagine': 666,\n"," 'horse': 667,\n"," 'heavy': 668,\n"," 'spirit': 669,\n"," 'position': 670,\n"," 'walking': 671,\n"," 'assure': 672,\n"," 'raised': 673,\n"," 'save': 674,\n"," 'pleased': 675,\n"," '“do': 676,\n"," 'talked': 677,\n"," 'earth': 678,\n"," 'floor': 679,\n"," 'entirely': 680,\n"," 'remained': 681,\n"," 'cry': 682,\n"," 'stepan': 683,\n"," 'happiness': 684,\n"," '“is': 685,\n"," 'uncle': 686,\n"," 'living': 687,\n"," 'shook': 688,\n"," 'trouble': 689,\n"," '“ah': 690,\n"," 'particular': 691,\n"," 'caught': 692,\n"," 'ladies': 693,\n"," 'exactly': 694,\n"," 'chance': 695,\n"," 'wished': 696,\n"," 'months': 697,\n"," 'women': 698,\n"," 'cause': 699,\n"," 'anxious': 700,\n"," 'beginning': 701,\n"," 'moved': 702,\n"," 'tone': 703,\n"," 'thus': 704,\n"," 'box': 705,\n"," 'wine': 706,\n"," 'real': 707,\n"," 'worth': 708,\n"," 'there’s': 709,\n"," 'society': 710,\n"," 'inquired': 711,\n"," 'natural': 712,\n"," 'fair': 713,\n"," 'shoulder': 714,\n"," 'remarked': 715,\n"," 'circumstances': 716,\n"," 'occasion': 717,\n"," 'sleep': 718,\n"," 'marriage': 719,\n"," 'figure': 720,\n"," 'lived': 721,\n"," 'try': 722,\n"," 'notice': 723,\n"," 'begin': 724,\n"," 'steps': 725,\n"," 'exclaimed': 726,\n"," 'line': 727,\n"," 'obliged': 728,\n"," 'murder': 729,\n"," 'loved': 730,\n"," 'die': 731,\n"," 'danger': 732,\n"," 'worse': 733,\n"," 'directly': 734,\n"," 'giving': 735,\n"," 'running': 736,\n"," 'watch': 737,\n"," 'whatever': 738,\n"," 'drawing': 739,\n"," 'probably': 740,\n"," 'madame': 741,\n"," 'slowly': 742,\n"," \"i've\": 743,\n"," 'further': 744,\n"," 'forgive': 745,\n"," 'length': 746,\n"," 'mouth': 747,\n"," 'although': 748,\n"," 'seven': 749,\n"," 'ha': 750,\n"," 'dora': 751,\n"," 'service': 752,\n"," 'died': 753,\n"," 'court': 754,\n"," 'hat': 755,\n"," 'latter': 756,\n"," 'whispered': 757,\n"," 'send': 758,\n"," 'fall': 759,\n"," 'office': 760,\n"," 'respect': 761,\n"," 'lie': 762,\n"," 'fortune': 763,\n"," 'listened': 764,\n"," 'roubles': 765,\n"," 'serious': 766,\n"," 'direction': 767,\n"," 'except': 768,\n"," 'stone': 769,\n"," 'knowledge': 770,\n"," 'muttered': 771,\n"," 'written': 772,\n"," 'arrived': 773,\n"," 'particularly': 774,\n"," 'allow': 775,\n"," 'passage': 776,\n"," 'play': 777,\n"," 'forgotten': 778,\n"," '“it’s': 779,\n"," 'public': 780,\n"," 'thank': 781,\n"," 'trust': 782,\n"," 'self': 783,\n"," 'quickly': 784,\n"," 'extraordinary': 785,\n"," 'settled': 786,\n"," 'yours': 787,\n"," 'trying': 788,\n"," 'comfort': 789,\n"," 'smiling': 790,\n"," 'reply': 791,\n"," 'papers': 792,\n"," 'distance': 793,\n"," 'drink': 794,\n"," 'forget': 795,\n"," 'cross': 796,\n"," 'necessary': 797,\n"," 'news': 798,\n"," 'marry': 799,\n"," 'effect': 800,\n"," 'burst': 801,\n"," 'listen': 802,\n"," 'stairs': 803,\n"," 'convinced': 804,\n"," 'coat': 805,\n"," 'gate': 806,\n"," 'wild': 807,\n"," 'view': 808,\n"," 'follow': 809,\n"," 'tea': 810,\n"," 'easy': 811,\n"," 'pay': 812,\n"," 'consider': 813,\n"," 'third': 814,\n"," 'believed': 815,\n"," 'bit': 816,\n"," 'terrible': 817,\n"," 'ashamed': 818,\n"," 'heaven': 819,\n"," 'meeting': 820,\n"," 'especially': 821,\n"," 'anyone': 822,\n"," 'seat': 823,\n"," 'curiosity': 824,\n"," 'hall': 825,\n"," 'absolutely': 826,\n"," 'breath': 827,\n"," 'determined': 828,\n"," 'church': 829,\n"," 'situation': 830,\n"," 'knowing': 831,\n"," 'closed': 832,\n"," 'leaving': 833,\n"," 'smiled': 834,\n"," 'silver': 835,\n"," '“to': 836,\n"," 'top': 837,\n"," 'duty': 838,\n"," 'shaking': 839,\n"," \"i'm\": 840,\n"," 'changed': 841,\n"," 'instantly': 842,\n"," 'engaged': 843,\n"," 'scarcely': 844,\n"," 'age': 845,\n"," 'shouted': 846,\n"," 'quick': 847,\n"," 'letters': 848,\n"," 'bound': 849,\n"," 'anne': 850,\n"," 'evidently': 851,\n"," 'judge': 852,\n"," 'supposed': 853,\n"," 'aware': 854,\n"," 'servant': 855,\n"," 'surely': 856,\n"," 'beg': 857,\n"," 'fodin': 858,\n"," 'instead': 859,\n"," 'started': 860,\n"," 'wood': 861,\n"," 'dress': 862,\n"," 'future': 863,\n"," 'spoken': 864,\n"," 'expect': 865,\n"," 'scene': 866,\n"," 'sun': 867,\n"," 'nearly': 868,\n"," 'pleasant': 869,\n"," 'desire': 870,\n"," 'clothes': 871,\n"," 'piece': 872,\n"," 'english': 873,\n"," 'plain': 874,\n"," 'pray': 875,\n"," 'fit': 876,\n"," 'free': 877,\n"," 'beautiful': 878,\n"," 'looks': 879,\n"," 'agreeable': 880,\n"," 'twice': 881,\n"," 'presence': 882,\n"," 'understood': 883,\n"," 'fixed': 884,\n"," 'glance': 885,\n"," 'questions': 886,\n"," 'grew': 887,\n"," 'stop': 888,\n"," 'confidence': 889,\n"," 'fresh': 890,\n"," 'shut': 891,\n"," 'pulled': 892,\n"," 'dropped': 893,\n"," 'threw': 894,\n"," 'human': 895,\n"," 'evidence': 896,\n"," 'frightened': 897,\n"," 'he’s': 898,\n"," 'green': 899,\n"," '“not': 900,\n"," 'shot': 901,\n"," 'england': 902,\n"," 'sign': 903,\n"," 'law': 904,\n"," 'outside': 905,\n"," 'train': 906,\n"," 'contrary': 907,\n"," 'mad': 908,\n"," 'former': 909,\n"," 'windows': 910,\n"," 'somewhat': 911,\n"," 'rooms': 912,\n"," 'affection': 913,\n"," 'carry': 914,\n"," 'safe': 915,\n"," 'difficult': 916,\n"," 'bright': 917,\n"," 'reading': 918,\n"," 'jew': 919,\n"," 'single': 920,\n"," 'paid': 921,\n"," 'evil': 922,\n"," 'greater': 923,\n"," 'appear': 924,\n"," 'strength': 925,\n"," 'grave': 926,\n"," \"won't\": 927,\n"," 'dog': 928,\n"," 'candle': 929,\n"," 'dreadful': 930,\n"," 'remembered': 931,\n"," 'quarter': 932,\n"," 'nobody': 933,\n"," 'sofa': 934,\n"," 'spot': 935,\n"," 'observe': 936,\n"," 'dressed': 937,\n"," 'farther': 938,\n"," 'devil': 939,\n"," 'speech': 940,\n"," 'satisfaction': 941,\n"," 'ourselves': 942,\n"," 'horses': 943,\n"," 'form': 944,\n"," 'private': 945,\n"," 'trees': 946,\n"," 'boys': 947,\n"," 'nonsense': 948,\n"," 'bell': 949,\n"," 'fool': 950,\n"," 'pride': 951,\n"," 'stranger': 952,\n"," 'delighted': 953,\n"," 'horror': 954,\n"," 'tall': 955,\n"," 'ship': 956,\n"," 'miles': 957,\n"," 'countenance': 958,\n"," 'easily': 959,\n"," 'ah': 960,\n"," 'o’clock': 961,\n"," 'ears': 962,\n"," 'prisoner': 963,\n"," 'drawn': 964,\n"," 'occurred': 965,\n"," 'influence': 966,\n"," 'number': 967,\n"," 'excellent': 968,\n"," 'mention': 969,\n"," 'offer': 970,\n"," 'facts': 971,\n"," 'important': 972,\n"," 'tongue': 973,\n"," 'pity': 974,\n"," 'blue': 975,\n"," 'hot': 976,\n"," \"can't\": 977,\n"," 'shoulders': 978,\n"," 'handsome': 979,\n"," 'terror': 980,\n"," 'complete': 981,\n"," 'fond': 982,\n"," '“they': 983,\n"," 'journey': 984,\n"," 'touch': 985,\n"," '“she': 986,\n"," 'spent': 987,\n"," 'beauty': 988,\n"," 'promise': 989,\n"," 'sharp': 990,\n"," 'crime': 991,\n"," 'considered': 992,\n"," 'break': 993,\n"," 'curious': 994,\n"," 'someone': 995,\n"," 'satisfied': 996,\n"," 'altogether': 997,\n"," 'waited': 998,\n"," 'mere': 999,\n"," 'eight': 1000,\n"," ...}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# dict 형태의 자료에 enumerate를 적용할 경우\n","a = {'hello':1, 'world':2, 'Esaa':5, 'statistics':10}\n","for index,word in enumerate(a):\n","  print(index,'/',word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tZIyVb18YS_N","executionInfo":{"status":"ok","timestamp":1652092388097,"user_tz":-540,"elapsed":265,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"f124a04f-f313-4983-f4fd-7969b93b4e10"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["0 / hello\n","1 / world\n","2 / Esaa\n","3 / statistics\n"]}]},{"cell_type":"code","source":["embedding_matrix = np.zeros((vocab_size, 100)) #300차원의 임베딩 매트릭스 생성\n","\n","for index, word in enumerate(vocabulary): #vocabulary에 있는 토큰들을 하나씩 넘겨줍니다.\n","    if word in glove: #넘겨 받은 토큰이 word2vec에 존재하면(이미 훈련이 된 토큰이라는 뜻)\n","        embedding_vector = glove[word] #해당 토큰에 해당하는 vector를 불러오고\n","        embedding_matrix[index] = embedding_vector #해당 위치의 embedding_mxtrix에 저장합니다.\n","    else:\n","        print(\"'\"+word+\"'는 glove에 없는 단어입니다.\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1idOZc_Opo_","executionInfo":{"status":"ok","timestamp":1652092668534,"user_tz":-540,"elapsed":276,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"e3c97c5f-1c2e-48fa-db16-f8c1c1524a96"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["'odin'는 glove에 없는 단어입니다.\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(vocab_size, 100,weights = [embedding_matrix], input_length = max_len))"],"metadata":{"id":"W38aLyq4OuK6","executionInfo":{"status":"ok","timestamp":1652092742317,"user_tz":-540,"elapsed":656,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["#4. Fasttext"],"metadata":{"id":"nYMibFgBQj8Y"}},{"cell_type":"code","source":["from gensim.models.keyedvectors import KeyedVectors\n","FastText = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/ESAA(22-1)/Week10/word-embeddings/word-embeddings/fasttext/fasttext.vec', binary = True,unicode_errors='ignore')"],"metadata":{"id":"Sc4PnFLcQmnl","executionInfo":{"status":"ok","timestamp":1652092819566,"user_tz":-540,"elapsed":10753,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["embedding_matrix = np.zeros((vocab_size, 300)) #300차원의 임베딩 매트릭스 생성\n","\n","for index, word in enumerate(vocabulary): #vocabulary에 있는 토큰들을 하나씩 넘겨줍니다.\n","    if word in word2vec: #넘겨 받은 토큰이 word2vec에 존재하면(이미 훈련이 된 토큰이라는 뜻)\n","        embedding_vector = word2vec[word] #해당 토큰에 해당하는 vector를 불러오고\n","        embedding_matrix[index] = embedding_vector #해당 위치의 embedding_mxtrix에 저장합니다."],"metadata":{"id":"1hTl8t1xRxsR","executionInfo":{"status":"ok","timestamp":1652092851879,"user_tz":-540,"elapsed":411,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(vocab_size, 300,weights = [embedding_matrix], input_length = max_len))"],"metadata":{"id":"8lreIXwGR2XE","executionInfo":{"status":"ok","timestamp":1652092864206,"user_tz":-540,"elapsed":423,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["#5. 대회 적용"],"metadata":{"id":"cvAGNXzbR5fZ"}},{"cell_type":"markdown","source":["##간단한 전처리 + 형태소 분석"],"metadata":{"id":"fNySox_5SuOS"}},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nm9SfTVRap9Y","executionInfo":{"status":"ok","timestamp":1652093021668,"user_tz":-540,"elapsed":7711,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"79cb7348-850e-4707-f2dc-daea3039697f"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 3.8 MB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","import re\n","import tqdm "],"metadata":{"id":"UkYaMKKwaofN","executionInfo":{"status":"ok","timestamp":1652093023376,"user_tz":-540,"elapsed":350,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","import re\n","import tqdm \n","\n","def text_preprocessing(text_list):\n","    \n","    stopwords = ['을', '를', '이', '가', '은', '는', 'null'] #불용어 설정\n","    tokenizer = Okt() #형태소 분석기 \n","    token_list = []\n","    \n","    for text in tqdm.tqdm(text_list):\n","        txt = re.sub('[^가-힣a-z]', ' ', text) #한글과 영어 소문자만 남기고 다른 글자 모두 제거\n","        token = tokenizer.morphs(txt) \n","        token = [t for t in token if t not in stopwords or type(t) != float] #형태소 분석 결과 중 stopwords에 해당하지 않는 것만 추출\n","        token_list.append(token)\n","        \n","    return token_list, tokenizer\n","\n","#형태소 분석기를 따로 저장한 이유는 후에 test 데이터 전처리를 진행할 때 이용해야 되기 때문 \n","train['token'], okt = text_preprocessing(train['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1CjdgpHEStE-","executionInfo":{"status":"ok","timestamp":1652094492112,"user_tz":-540,"elapsed":395092,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"24c0c865-cdac-4a07-9572-f5f6f4bfef70"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 54879/54879 [06:34<00:00, 138.98it/s]\n"]}]},{"cell_type":"markdown","source":["##Vectorization"],"metadata":{"id":"EhvX89bvay0e"}},{"cell_type":"code","source":["def text2sequence(train_text, max_len=1000):\n","    \n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(train_text)\n","    train_X_seq = tokenizer.texts_to_sequences(train_text)\n","    vocab_size = len(tokenizer.word_index) + 1 #모델에게 알려줄 vocabulary의 크기 계산 \n","    print('vocab_size : ', vocab_size)\n","    X_train = pad_sequences(train_X_seq, maxlen = max_len) #설정한 문장의 최대 길이만큼 padding\n","    return X_train, vocab_size, tokenizer\n","\n","train_y = train['author']\n","train_X, vocab_size, vectorizer = text2sequence(train['token'], max_len = 100)\n","print(train_X.shape, train_y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8sEA8_AfayCi","executionInfo":{"status":"ok","timestamp":1652094498382,"user_tz":-540,"elapsed":3328,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"05ce95d8-8cb1-42d6-c922-d2976e4d7b94"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab_size :  36342\n","(54879, 100) (54879,)\n"]}]},{"cell_type":"markdown","source":["##Embedding"],"metadata":{"id":"sFhDUEZYbHW6"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/ESAA(22-1)/Week10')"],"metadata":{"id":"sfHngID3giuN","executionInfo":{"status":"ok","timestamp":1652094547486,"user_tz":-540,"elapsed":274,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary = True)\n","embedding_matrix = np.zeros((vocab_size, 300)) "],"metadata":{"id":"KDBqpZZihWuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for index, word in enumerate(vocabulary): \n","    if word in word2vec:  \n","        embedding_vector = word2vec[word] \n","        embedding_matrix[index] = embedding_vector\n","    else:\n","        print(\"word2vec에 없는 단어입니다.\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihQSF9IXbIfA","executionInfo":{"status":"ok","timestamp":1652094763027,"user_tz":-540,"elapsed":254,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"14226cd2-508f-470a-a06b-31bde0a6d7f0"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["word2vec에 없는 단어입니다.\n"]}]},{"cell_type":"markdown","source":["##Modeling"],"metadata":{"id":"X9yXcXZqbKqF"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation, Embedding\n","\n","def LSTM(vocab_size, max_len=1000):\n","    model = Sequential()\n","    #Sequential 모델은 층을 순서대로 쌓은 것으로, 아래와 같이 각 층 인스턴스를 리스트 형식으로 나열\n","\n","    model.add(Embedding(vocab_size, 300,weights = [embedding_matrx], input_length = max_len)) #임베딩 가중치 적용 코드\n","    model.add(SpatialDropout1D(0.3)) #입력 벡터 중 30%만큼 층의 출력을 줄여\n","    model.add(LSTM(64)) #64 차원의 단일 벡터를 반환\n","    model.add(Dropout(0.5)) #학습과정 중 각 업데이트에서 임의로 인풋유닛을 0으로 설정하는 비율 0.5로 설정\n","    model.add(Dense(64, activation='relu', kernel_regularizer = regularizers.l2(0.001))) #64차원 출력에 'relu' 함수를 적용\n","    model.add(Dense(1, activation='sigmoid')) #1차원 출력에 'sigmoid' 함수를 적용\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n","    model.summary()\n","    return model"],"metadata":{"id":"xR19c9C6bLq_","executionInfo":{"status":"ok","timestamp":1652094766129,"user_tz":-540,"elapsed":255,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":57,"outputs":[]}]}