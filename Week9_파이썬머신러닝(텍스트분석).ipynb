{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week9_파이썬머신러닝(텍스트분석).ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"13Chp1qUbEJWh4g949_68dyp7gYDwNZr_","authorship_tag":"ABX9TyN2U61oaOwo4lNZjZ637nf0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#텍스트 분석 수행 프로세스 \n","1. 텍스트 사전 준비작업(텍스트 전처리)\n","2. 피처 벡터화/추출\n","3. ML 모델 수립 및 학습/예측/평가"],"metadata":{"id":"f-D8MwaytqPJ"}},{"cell_type":"markdown","source":["##02. 텍스트 사전 준비 작업(텍스트 전처리) - 텍스트 정규화\n","\n","\n","*   클렌징\n","*   텍스트 토큰화\n","\n","\n","    *   문장 토큰화 : 문장의 마침표(.),개행문자(\\n) 등 문장의 마지막을 뜻하는 기호에 따라 분리하는 것이 일반적  ex) sent_tokenize()\n","    *   단어 토큰화 : 기본적으로 공백, 콤마(,), 마침표(.), 개행문자 등으로 단어를 분리하지만, 정규 표현식을 이용해 다양한 유형으로 토큰화를 수행할 수 있다.단어의 순서가 중요하지 않은 경우 문장 토큰화를 사용하지 않고 단어 토큰화만 사용해도 충분하다.\n","\n","\n","\n"],"metadata":{"id":"35Zp_1oIt5jv"}},{"cell_type":"markdown","source":["###문장 토큰화"],"metadata":{"id":"5vi-Ptu1yiCK"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnyxS93StbQY","executionInfo":{"status":"ok","timestamp":1651461785254,"user_tz":-540,"elapsed":1512,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"2f7aed40-4151-4d93-ab13-a344179f03e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["from nltk import sent_tokenize\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","source":["text_sample = 'The Matrix is everywhere its all around us, here even in this room. You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes.'\n","\n","sentences = sent_tokenize(text=text_sample)\n","print(type(sentences),len(sentences))\n","print(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHQ3BQZOyt3N","executionInfo":{"status":"ok","timestamp":1651462025911,"user_tz":-540,"elapsed":421,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"71b579d9-3a24-4e81-f739-c79602f9e3f4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'> 3\n","['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"]}]},{"cell_type":"markdown","source":["sent_tokenize()가 반환하는 것은 각각의 문장으로 구성된 list 객체이다. 반환된 list 객체가 3개의 문장으로 된 문자열을 가지고 있는 것을 알 수 있다."],"metadata":{"id":"Sszlih9kzt-W"}},{"cell_type":"markdown","source":["###단어 토큰화"],"metadata":{"id":"aQspGdwCz3o6"}},{"cell_type":"code","source":["from nltk import word_tokenize"],"metadata":{"id":"uujyvB0gzTmm","executionInfo":{"status":"ok","timestamp":1651462100265,"user_tz":-540,"elapsed":6,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["sentence = \"The matrix is everywhere its all around us, here even in this room.\"\n","words = word_tokenize(sentence)\n","print(type(words),len(words))\n","print(words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7swADYlz88t","executionInfo":{"status":"ok","timestamp":1651462173378,"user_tz":-540,"elapsed":389,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"7aed3d11-06d9-48a7-a1e9-a80e2fff990a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'> 15\n","['The', 'matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"]}]},{"cell_type":"code","source":["from nltk import word_tokenize, sent_tokenize\n","\n","#여러 개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화하게 만드는 함수 생성\n","def tokenize_text(text):\n","    #문장별로 분리 토큰\n","    sentences = sent_tokenize(text)\n","    #분리된 문장별 단어 토큰화\n","    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n","    return word_tokens\n","\n","#여러 문장에 대해 문장별 단어 토큰화 수행.\n","word_tokens = tokenize_text(text_sample)\n","print(type(word_tokens),len(word_tokens))\n","print(word_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xuXtvFuh0O9S","executionInfo":{"status":"ok","timestamp":1651462392798,"user_tz":-540,"elapsed":401,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"99aa9ccb-587b-4e9a-af7c-c10ab12152f3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'> 3\n","[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"]}]},{"cell_type":"markdown","source":["문장을 단어별로 하나씩 토큰화할 경우 문맥적인 의미는 무시될 수밖에 없다. 이러한 문제를 조금이라도 해결해 보고자 도입된 것이 n-gram이다.  \n","n-gram : 연속된 n개의 단어를 하나의 토큰화 단위로 분리해 내는 것"],"metadata":{"id":"96RQThK-1P4h"}},{"cell_type":"markdown","source":["###스톱 워드 제거  \n","스톱 워드(stop word)는 분석에 큰 의미가 없는 단어 지징한다. 가령 영어에서 is, the, a , will 등 문장을 구성하는 필수 문법 요소지만 문맥적으로 큰 의미가 없는 단어가 이에 해당한다."],"metadata":{"id":"3XwlX7VX1fIa"}},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVa590yQ1CjJ","executionInfo":{"status":"ok","timestamp":1651462591466,"user_tz":-540,"elapsed":5,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"b467365d-fd46-40a5-c230-4bc5712560e5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["NTLK의 english의 경우 몇 개의 stopwords 가 있는지 알아보고 그중 20개만 확인해보자."],"metadata":{"id":"FZJZRlRO11oh"}},{"cell_type":"code","source":["print('영어 stop words 개수:',len(nltk.corpus.stopwords.words('english')))\n","print(nltk.corpus.stopwords.words('english')[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yge32uOy1010","executionInfo":{"status":"ok","timestamp":1651462682813,"user_tz":-540,"elapsed":5,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"842c9131-a71e-495f-84f5-575e5c3a6e28"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["영어 stop words 개수: 179\n","['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"]}]},{"cell_type":"markdown","source":["영어의 경우 스톱 워드의 개수가 179개이며, 그중 20개만 살펴보면 위의 결과와 같다."],"metadata":{"id":"GiaPhNed2MqU"}},{"cell_type":"code","source":["import nltk\n","\n","stopwords = nltk.corpus.stopwords.words('english')\n","all_tokens =[]\n","#위 예제에서 3개의 문장별로 얻은 word_tokens list 에 대해 스톱 워드를 제거하는 반복문\n","for sentence in word_tokens:\n","    filtered_words=[]\n","    #개별 문장별로 토큰화된 문장 list에 대해 스톱 워드를 제거하는 반복문\n","    for word in sentence:\n","        #소문자로 모두 변환합니다.\n","        word = word.lower()\n","        #토큰화된 개별 단어가 스톱 워드의 단어에 포함되지 않으면 word_tokens에 추가\n","        if word not in stopwords:\n","            filtered_words.append(word)\n","    all_tokens.append(filtered_words)\n","\n","print(all_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9KNPhIY2LCg","executionInfo":{"status":"ok","timestamp":1651463011019,"user_tz":-540,"elapsed":408,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"c1a8b431-b1f5-48d8-dad3-7b409706a54a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"]}]},{"cell_type":"markdown","source":["is,this와 같은 스톱 워드가 필터링을 통해 제거됐음을 알 수 있다."],"metadata":{"id":"0rqWGCMl3c-w"}},{"cell_type":"markdown","source":["###Stemming과 Lemmatization  \n","Stemming : 원형 단어로 변환 시 일반적인 방법을 적용하거나 더 단순화된 방법을 적용해 원래 단어에서 일부 철자가 훼손된 어근 단어를 추출하는 경향이 있다.  \n","Lemmatization : 품사와 같은 문법적인 요소와 더 의미적인 부분을 감안해 정확한 철자로 된 어근 단어를 찾아준다."],"metadata":{"id":"uXBBZs5F3h6v"}},{"cell_type":"markdown","source":["Stemming"],"metadata":{"id":"nhsKJWwn3mSd"}},{"cell_type":"code","source":["from nltk.stem import LancasterStemmer\n","stemmer = LancasterStemmer()\n","\n","print(stemmer.stem('working'), stemmer.stem('works'),stemmer.stem('worked'))\n","print(stemmer.stem('amusing'), stemmer.stem('amuses'), stemmer.stem('amused'))\n","print(stemmer.stem('happier'), stemmer.stem('happiest'))\n","print(stemmer.stem('fancier'), stemmer.stem('fanciest'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-MYzIdz3bPx","executionInfo":{"status":"ok","timestamp":1651463259438,"user_tz":-540,"elapsed":440,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"de23bae3-619c-4be6-8ad0-896ae191168b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["work work work\n","amus amus amus\n","happy happiest\n","fant fanciest\n"]}]},{"cell_type":"markdown","source":["Lemmatization  \n","정확한 원형 단어 추출을 위해 단어의 '품사'를 입력해줘야 한다."],"metadata":{"id":"MmGUUzB34asX"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","import nltk\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GWeb6qeg4X52","executionInfo":{"status":"ok","timestamp":1651463331486,"user_tz":-540,"elapsed":1076,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"40e22c19-a4a9-4719-c418-ea9da1df5d64"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["lemma = WordNetLemmatizer()\n","print(lemma.lemmatize('amusing','v'), lemma.lemmatize('amuses','v'), lemma.lemmatize('amused','v'))\n","print(lemma.lemmatize('happier','a'), lemma.lemmatize('happiest','a'))\n","print(lemma.lemmatize('fancier','a'), lemma.lemmatize('fanciest','a'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EC8ox9qi4paT","executionInfo":{"status":"ok","timestamp":1651463442349,"user_tz":-540,"elapsed":2178,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"c9700935-3cbc-40af-ff51-e94388506fa3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["amuse amuse amuse\n","happy happy\n","fancy fancy\n"]}]},{"cell_type":"markdown","source":["##03. Bag of Words - BOW  \n","Bag of Words 모델은 문서가 가지는 모든 단어(words)를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여해 피처 값을 추출하는 모델"],"metadata":{"id":"j5nlOeqxQQ2S"}},{"cell_type":"markdown","source":["###BOW 피처 벡터화  \n","각 문서(Document)의 텍스트를 단어로 추출해 피처로 할당하고, 각 단어의 발생 빈도와 같은 값을 피처에 값으로 부여해 각 문서를 이 단어 피처의 발생 빈도 값으로 구성된 벡터로 만드는 기법"],"metadata":{"id":"gZuXHrAlQiNN"}},{"cell_type":"markdown","source":["\n","\n","*   사이킷런의 Count 및 TF-IDF 벡터화 구현:CountVectorizer, TfidfVectorizer\n","\n"],"metadata":{"id":"gYAfscnoQ7qp"}},{"cell_type":"markdown","source":["CountVectorizer 클래스 : 카운트 기반의 벡터화를 구현한 클래스  \n","단지 피처 벡터화만 수행하지는 않으며 소문자 일괄 변환, 토큰화, 스톱 워드 필터링 등의 텍스트 전처리도 함께 수행  "],"metadata":{"id":"mMrwnHCLRF9S"}},{"cell_type":"markdown","source":["1. 영어의 경우, 모든 문자를 소문자로 변경하는 등의 전처리 작업을 수행\n","2. 디폴트로 단어 기준으로 n_gram_range를 반영해 각 단어를 토큰화  \n","3. 텍스트 정규화를 수행한다.  \n","stop words만 수행, stemmer, lemmatize는 CountVectorizer 자체에서는 지원되지 않음. 이를 위한 함수를 만들거나 외부 패키지로 미리 Text Normalization 수행 필요  \n","4. max_df, min_df, max_features 등의 파라미터를 반영하여 Token된 단어들을 feature extraction 후 vectorization 적용  "],"metadata":{"id":"ElbmYuyXRa20"}},{"cell_type":"markdown","source":["###희소 행렬-COO 형식  \n","0이 아닌 데이터만 별도의 데이터 배열(Array)에 저장하고, 그 데이터가 가리키는 행과 열의 위치를 별도의 배열로 저장하는 방식 "],"metadata":{"id":"GVLETR0jSPNr"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"b-lCyLxA5EPV","executionInfo":{"status":"ok","timestamp":1651470094962,"user_tz":-540,"elapsed":468,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["dense = np.array([[3,0,1],[0,2,0]])\n","dense"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tacNeUIXSc6J","executionInfo":{"status":"ok","timestamp":1651470144455,"user_tz":-540,"elapsed":408,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"37d69812-f55f-4bf1-9dcd-6e1fe418a420"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3, 0, 1],\n","       [0, 2, 0]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["from scipy import sparse"],"metadata":{"id":"1dTdd6ZbSn8N","executionInfo":{"status":"ok","timestamp":1651470159050,"user_tz":-540,"elapsed":831,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#0이 아닌 데이터 추출\n","data = np.array([3,1,2])\n","\n","#행 위치와 열 위치를 각각 배열로 생성\n","row_pos = np.array([0,1,1])\n","col_pos = np.array([0,2,1])\n","\n","#sparse 패키지의 coo_matrix를 이용해 COO 형식으로 희소 행렬 생성\n","sparse_coo = sparse.coo_matrix((data,(row_pos,col_pos)))"],"metadata":{"id":"ZXTarvw_SrDt","executionInfo":{"status":"ok","timestamp":1651470270582,"user_tz":-540,"elapsed":416,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["sparse_coo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhgDYBIJTFE9","executionInfo":{"status":"ok","timestamp":1651470277772,"user_tz":-540,"elapsed":424,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"7a492cbf-3fd7-4905-eed4-aab8f9c6506a"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2x3 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 3 stored elements in COOrdinate format>"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["#다시 밀집 형태의 행렬로 출력\n","sparse_coo.toarray()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J374-qvLTJgb","executionInfo":{"status":"ok","timestamp":1651470307012,"user_tz":-540,"elapsed":393,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"d4ca8e91-a076-4823-a530-1047ff009bfa"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3, 0, 0],\n","       [0, 2, 1]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["###희소 행렬-CSR 형식  \n",":COO 형식이 행과 열의 위치를 나타내기 위해서 반복적인 위치 데이터를 사용해야 하는 문제점을 해결한 방식   \n","[행 위치 배열의 고유값 시작 인덱스 배열] + [총 항목 개수 배열] = [행 위치 배열의 고유값 시작 인덱스 배열 최종]"],"metadata":{"id":"k4QWRf9ETRaV"}},{"cell_type":"code","source":["from scipy import sparse"],"metadata":{"id":"WeJjyouqTQgQ","executionInfo":{"status":"ok","timestamp":1651470414256,"user_tz":-540,"elapsed":678,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["dense2 = np.array([[0,0,1,0,0,5],\n","                   [1,4,0,3,2,5],\n","                   [0,6,0,3,0,0],\n","                   [2,0,0,0,0,0],\n","                   [0,0,0,7,0,8],\n","                   [1,0,0,0,0,0]])\n","\n","#0이 아닌 데이터 추출\n","data2 = np.array([1,5,1,4,3,2,5,6,3,2,7,8,1])\n","\n","#행 위치와 열 위치를 각각 array로 새성\n","row_pos = np.array([0,0,1,1,1,1,1,2,2,3,4,4,5])\n","col_pos = np.array([2,5,0,1,3,4,5,1,3,0,3,5,0])\n","\n","#COO 형식으로 변환\n","sparse_coo = sparse.coo_matrix((data2,(row_pos,col_pos)))\n","\n","#행 위치 배열의 고유한 값의 시작 위치 인덱스를 배열로 생성\n","row_pos_ind = np.array([0,2,7,9,10,12,13])\n","\n","#CSR 형식으로 변환\n","sparse_csr = sparse.csr_matrix((data2,col_pos,row_pos_ind))\n","\n","print('COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n","print(sparse_coo.toarray())\n","print('CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n","print(sparse_csr.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_WLN5nZTqqD","executionInfo":{"status":"ok","timestamp":1651470895347,"user_tz":-540,"elapsed":470,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"3c07deca-5d3a-48b2-cce3-071f137b9d92"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n","[[0 0 1 0 0 5]\n"," [1 4 0 3 2 5]\n"," [0 6 0 3 0 0]\n"," [2 0 0 0 0 0]\n"," [0 0 0 7 0 8]\n"," [1 0 0 0 0 0]]\n","CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n","[[0 0 1 0 0 5]\n"," [1 4 0 3 2 5]\n"," [0 6 0 3 0 0]\n"," [2 0 0 0 0 0]\n"," [0 0 0 7 0 8]\n"," [1 0 0 0 0 0]]\n"]}]},{"cell_type":"markdown","source":["##05.감성 분석"],"metadata":{"id":"_hmF6N19dzJr"}},{"cell_type":"markdown","source":["###지도학습 기반 감성 분석 실습 - IMDB 영화평"],"metadata":{"id":"xUOXgKrTd2VG"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"PlcA9GrCVVVt","executionInfo":{"status":"ok","timestamp":1651473107122,"user_tz":-540,"elapsed":394,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["review_df = pd.read_csv('/content/drive/MyDrive/ESAA(22-1)/Week9/IMDB 영화평 데이터/labeledTrainData/labeledTrainData.tsv',\n","                        header=0, sep='\\t', quoting=3)\n","review_df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"WPYWU0UId8Ua","executionInfo":{"status":"ok","timestamp":1651473175683,"user_tz":-540,"elapsed":1936,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"ae6fb49a-59dd-44dc-e142-98e92cd3c1ff"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id  sentiment                                             review\n","0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n","1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n","2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."],"text/html":["\n","  <div id=\"df-ddeb5e5a-4448-4b07-a1af-f408cf4d0659\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"5814_8\"</td>\n","      <td>1</td>\n","      <td>\"With all this stuff going down at the moment ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>\"2381_9\"</td>\n","      <td>1</td>\n","      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"7759_3\"</td>\n","      <td>0</td>\n","      <td>\"The film starts with a manager (Nicholas Bell...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddeb5e5a-4448-4b07-a1af-f408cf4d0659')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ddeb5e5a-4448-4b07-a1af-f408cf4d0659 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ddeb5e5a-4448-4b07-a1af-f408cf4d0659');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["\n","\n","\n","\n","*   id : 각 데이터의 id\n","*   sentiment : 영화평(review)의 Sentiment 결과 값(Target Label). 1은 긍정적 평가, 0은 부정적 평가를 의미합니다.  \n","*   review : 영화평의 텍스트\n","\n","\n","\n","\n","\n"],"metadata":{"id":"VzL9Ym9ReOrv"}},{"cell_type":"code","source":["print(review_df['review'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTY-_hU1d_6K","executionInfo":{"status":"ok","timestamp":1651473290100,"user_tz":-540,"elapsed":395,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"aded6a13-ebc1-4f84-c566-7f73fe311715"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"]}]},{"cell_type":"code","source":["import re "],"metadata":{"id":"urs-Q196emdN","executionInfo":{"status":"ok","timestamp":1651473299891,"user_tz":-540,"elapsed":392,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["#<br> html 태그는 replace 함수로 공백으로 변환\n","review_df['review'] = review_df['review'].str.replace('<br />',' ')\n","\n","#파이썬의 정규 표현식 모듈인 re를 이용해 영어 문자열이 아닌 문자는 모두 공백으로 변환\n","review_df['review'] = review_df['review'].apply(lambda x:re.sub('[^a-zA-Z]',' ',x))"],"metadata":{"id":"nCOGFjGFerWf","executionInfo":{"status":"ok","timestamp":1651473424872,"user_tz":-540,"elapsed":3002,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","class_df = review_df['sentiment']\n","feature_df = review_df.drop(['id','sentiment'],axis=1,inplace=False)"],"metadata":{"id":"AKeDJXDCfJQh","executionInfo":{"status":"ok","timestamp":1651473491864,"user_tz":-540,"elapsed":388,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["X_train,X_test,y_train,y_test = train_test_split(feature_df,class_df,test_size=0.3, random_state=156)\n","X_train.shape, X_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mx1CqebXfaPy","executionInfo":{"status":"ok","timestamp":1651473542477,"user_tz":-540,"elapsed":392,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"33cbb585-748e-4e5b-c1d8-0d9f9d145e4f"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((17500, 1), (7500, 1))"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, roc_auc_score"],"metadata":{"id":"zTP35nmifmmr","executionInfo":{"status":"ok","timestamp":1651473663421,"user_tz":-540,"elapsed":3,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["**Count 벡터화 적용**"],"metadata":{"id":"oJwc3ajahRUu"}},{"cell_type":"code","source":["#스톱 워드는 English,filtering,ngram 은 (1,2)로 설정해 CountVectorization 수행\n","#LogisticRegression의 C는 10으로 설정.\n","pipeline = Pipeline([('cnt_vect',CountVectorizer(stop_words='english', ngram_range=(1,2))),\n","                      ('lr_clf',LogisticRegression(C=10))])\n","\n","#Pipeline 객체를 이ㅛㅇ해 fit(), predict() 로 학습/예측 수행. predict_proba()는 roc_auc 때문에 수행\n","pipeline.fit(X_train['review'],y_train)\n","pred = pipeline.predict(X_test['review'])\n","pred_probs = pipeline.predict_proba(X_test['review'])[:,-1]\n","\n","print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test,pred), roc_auc_score(y_test,pred_probs)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vo-uSaPZf-Us","executionInfo":{"status":"ok","timestamp":1651474030678,"user_tz":-540,"elapsed":69498,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"4aeaa5dd-e866-4b45-c85c-563a81aae5f2"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["예측 정확도는 0.8860, ROC-AUC는 0.9503\n"]}]},{"cell_type":"markdown","source":["**TF-IDF 벡터화 적용**"],"metadata":{"id":"UeWbY-2UhVQU"}},{"cell_type":"code","source":["#스톱 워드는 english,filtering,ngram은 (1,2)로 설정해 TF-IDF 벡터화 수행\n","#LogisticRegression의 C는 10으로 수행\n","pipeline = Pipeline([('tfidf_vect',TfidfVectorizer(stop_words='english',ngram_range=(1,2))),\n","                     ('lr_clf',LogisticRegression(C=10))])\n","pipeline.fit(X_train['review'],y_train)\n","pred = pipeline.predict(X_test['review'])\n","pred_probs = pipeline.predict_proba(X_test['review'])[:,1]\n","\n","print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test,pred),roc_auc_score(y_test,pred_probs)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOBvZRJ8hKU-","executionInfo":{"status":"ok","timestamp":1651474365943,"user_tz":-540,"elapsed":36942,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"9640360b-67e0-48fb-b37f-13e292c9c6ee"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["예측 정확도는 0.8936, ROC-AUC는 0.9598\n"]}]},{"cell_type":"markdown","source":["TF-IDF 기반 피처 벡터화의 예측 성능이 조금 더 나아졌다."],"metadata":{"id":"iT0Aegcdix5s"}},{"cell_type":"markdown","source":["###비지도학습 기반 감성 분석 소개"],"metadata":{"id":"FxwoJ58Xint7"}},{"cell_type":"markdown","source":["많은 감성 분석용 데이터는 레이블 값을 가지고 있지 않다. 이러한 경우에 Lexicon 이 유용하게 사용될 수 있다. "],"metadata":{"id":"qAJ-eV_Niq4y"}},{"cell_type":"markdown","source":["Lexicon : 감성만을 분석하기 위해 지원하는 감성 어휘 사전"],"metadata":{"id":"yedYk2gTi4ym"}},{"cell_type":"markdown","source":["###SentiWordNet을 이용한 감성 분석"],"metadata":{"id":"sUT2zUzDjA_y"}},{"cell_type":"markdown","source":["WordNet Synset과 SentiWordNet SentiSynset 클래스의 이해"],"metadata":{"id":"PYoG5jV6jImQ"}},{"cell_type":"code","source":["import nltk\n","nltk.download('all')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xDW0MJ3iVFl","executionInfo":{"status":"ok","timestamp":1651474660626,"user_tz":-540,"elapsed":127851,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"a81ddd43-2581-44d8-9ec0-90bb05086160"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/extended_omw.zip.\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw.zip.\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Package punkt is already up-to-date!\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Package wordnet is already up-to-date!\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["from nltk.corpus import wordnet as wn\n","\n","term = 'present'\n","\n","#'present' 라는 단어로 wordnet의 synsets 생성\n","synsets = wn.synsets(term)\n","print('synsets() 반환 type:',type(synsets))\n","print('synsets() 반환 값 개수:',len(synsets))\n","print('synsets() 반환 값:',synsets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npTEWb-_jYfO","executionInfo":{"status":"ok","timestamp":1651474680750,"user_tz":-540,"elapsed":423,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"d2701e3d-b58f-4250-ea79-f6bd73266e14"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["synsets() 반환 type: <class 'list'>\n","synsets() 반환 값 개수: 18\n","synsets() 반환 값: [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"]}]},{"cell_type":"markdown","source":["총 18개의 서로 다른 semantic을 가지는 synset 객체가 반환되었다."],"metadata":{"id":"TF9-PL4pj1VP"}},{"cell_type":"code","source":["for synset in synsets:\n","    print('##### Synset name : ',synset.name(),'#####')\n","    print('POS:',synset.lexname())\n","    print('Definition:', synset.definition())\n","    print('Lemmas:',synset.lemma_names())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDsr3jBxj8tU","executionInfo":{"status":"ok","timestamp":1651474814910,"user_tz":-540,"elapsed":475,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"e798df3c-29a2-4073-ae9e-a0ab342b67ac"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["##### Synset name :  present.n.01 #####\n","POS: noun.time\n","Definition: the period of time that is happening now; any continuous stretch of time including the moment of speech\n","Lemmas: ['present', 'nowadays']\n","##### Synset name :  present.n.02 #####\n","POS: noun.possession\n","Definition: something presented as a gift\n","Lemmas: ['present']\n","##### Synset name :  present.n.03 #####\n","POS: noun.communication\n","Definition: a verb tense that expresses actions or states at the time of speaking\n","Lemmas: ['present', 'present_tense']\n","##### Synset name :  show.v.01 #####\n","POS: verb.perception\n","Definition: give an exhibition of to an interested audience\n","Lemmas: ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n","##### Synset name :  present.v.02 #####\n","POS: verb.communication\n","Definition: bring forward and present to the mind\n","Lemmas: ['present', 'represent', 'lay_out']\n","##### Synset name :  stage.v.01 #####\n","POS: verb.creation\n","Definition: perform (a play), especially on a stage\n","Lemmas: ['stage', 'present', 'represent']\n","##### Synset name :  present.v.04 #####\n","POS: verb.possession\n","Definition: hand over formally\n","Lemmas: ['present', 'submit']\n","##### Synset name :  present.v.05 #####\n","POS: verb.stative\n","Definition: introduce\n","Lemmas: ['present', 'pose']\n","##### Synset name :  award.v.01 #####\n","POS: verb.possession\n","Definition: give, especially as an honor or reward\n","Lemmas: ['award', 'present']\n","##### Synset name :  give.v.08 #####\n","POS: verb.possession\n","Definition: give as a present; make a gift of\n","Lemmas: ['give', 'gift', 'present']\n","##### Synset name :  deliver.v.01 #####\n","POS: verb.communication\n","Definition: deliver (a speech, oration, or idea)\n","Lemmas: ['deliver', 'present']\n","##### Synset name :  introduce.v.01 #####\n","POS: verb.communication\n","Definition: cause to come to know personally\n","Lemmas: ['introduce', 'present', 'acquaint']\n","##### Synset name :  portray.v.04 #####\n","POS: verb.creation\n","Definition: represent abstractly, for example in a painting, drawing, or sculpture\n","Lemmas: ['portray', 'present']\n","##### Synset name :  confront.v.03 #####\n","POS: verb.communication\n","Definition: present somebody with something, usually to accuse or criticize\n","Lemmas: ['confront', 'face', 'present']\n","##### Synset name :  present.v.12 #####\n","POS: verb.communication\n","Definition: formally present a debutante, a representative of a country, etc.\n","Lemmas: ['present']\n","##### Synset name :  salute.v.06 #####\n","POS: verb.communication\n","Definition: recognize with a gesture prescribed by a military regulation; assume a prescribed position\n","Lemmas: ['salute', 'present']\n","##### Synset name :  present.a.01 #####\n","POS: adj.all\n","Definition: temporal sense; intermediate between past and future; now existing or happening or in consideration\n","Lemmas: ['present']\n","##### Synset name :  present.a.02 #####\n","POS: adj.all\n","Definition: being or existing in a specified place\n","Lemmas: ['present']\n"]}]},{"cell_type":"markdown","source":["path_similarity() 메서드 : 단어 간의 유사도를 나타내줌"],"metadata":{"id":"hQt1i3I-khND"}},{"cell_type":"code","source":["#synset 객체를 단어별로 생성합니다.\n","tree = wn.synset('tree.n.01')\n","lion = wn.synset('lion.n.01')\n","tiger = wn.synset('tiger.n.02')\n","cat = wn.synset('cat.n.01')\n","dog = wn.synset('dog.n.01')\n","\n","entities = [tree,lion,tiger,cat,dog]\n","similarities = []\n","entity_names = [entity.name().split(',')[0] for entity in entities]\n","\n","#단어별 synset 을 반복하면서 다른 단어의 synset과 유사도를 측정합니다.\n","for entity in entities:\n","    similarity = [round(entity.path_similarity(compared_entity),2) for compared_entity in entities]\n","    similarities.append(similarity)\n","\n","#개별 단어별 synset과 다른 단어의 synset과의 유사도르 DataFrame 형태로 저장합니다.\n","similarity_df = pd.DataFrame(similarities,columns=entity_names,index=entity_names)\n","similarity_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"UxtVAPJYkTzb","executionInfo":{"status":"ok","timestamp":1651475256762,"user_tz":-540,"elapsed":7,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"49afdcbf-d8e5-4499-a471-df651c1f8b48"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            tree.n.01  lion.n.01  tiger.n.02  cat.n.01  dog.n.01\n","tree.n.01        1.00       0.07        0.07      0.08      0.12\n","lion.n.01        0.07       1.00        0.33      0.25      0.17\n","tiger.n.02       0.07       0.33        1.00      0.25      0.17\n","cat.n.01         0.08       0.25        0.25      1.00      0.20\n","dog.n.01         0.12       0.17        0.17      0.20      1.00"],"text/html":["\n","  <div id=\"df-778167ca-82e1-4f97-a900-d02f91d2f61f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tree.n.01</th>\n","      <th>lion.n.01</th>\n","      <th>tiger.n.02</th>\n","      <th>cat.n.01</th>\n","      <th>dog.n.01</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>tree.n.01</th>\n","      <td>1.00</td>\n","      <td>0.07</td>\n","      <td>0.07</td>\n","      <td>0.08</td>\n","      <td>0.12</td>\n","    </tr>\n","    <tr>\n","      <th>lion.n.01</th>\n","      <td>0.07</td>\n","      <td>1.00</td>\n","      <td>0.33</td>\n","      <td>0.25</td>\n","      <td>0.17</td>\n","    </tr>\n","    <tr>\n","      <th>tiger.n.02</th>\n","      <td>0.07</td>\n","      <td>0.33</td>\n","      <td>1.00</td>\n","      <td>0.25</td>\n","      <td>0.17</td>\n","    </tr>\n","    <tr>\n","      <th>cat.n.01</th>\n","      <td>0.08</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>1.00</td>\n","      <td>0.20</td>\n","    </tr>\n","    <tr>\n","      <th>dog.n.01</th>\n","      <td>0.12</td>\n","      <td>0.17</td>\n","      <td>0.17</td>\n","      <td>0.20</td>\n","      <td>1.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-778167ca-82e1-4f97-a900-d02f91d2f61f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-778167ca-82e1-4f97-a900-d02f91d2f61f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-778167ca-82e1-4f97-a900-d02f91d2f61f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["lion은 tree와의 유사도가 0.07로 가장 적고, tiger와는 유사도가 0.33으로 가장 큼."],"metadata":{"id":"umLQxkt-mL2Q"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import sentiwordnet as swn"],"metadata":{"id":"DLUu6e75mFHF","executionInfo":{"status":"ok","timestamp":1651475360244,"user_tz":-540,"elapsed":491,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["senti_synsets = list(swn.senti_synsets('slow'))\n","print('senti_synsets() 반환 type:',type(senti_synsets))\n","print('senti_synsets() 반환 값 개수:', len(senti_synsets))\n","print('senti_synsets() 반환 값:', senti_synsets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLxx43iKmYx4","executionInfo":{"status":"ok","timestamp":1651475438602,"user_tz":-540,"elapsed":409,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"0a1eb43c-707c-4362-bfe4-1c3c16b9999c"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["senti_synsets() 반환 type: <class 'list'>\n","senti_synsets() 반환 값 개수: 11\n","senti_synsets() 반환 값: [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"]}]},{"cell_type":"markdown","source":["SentiSynset 객체는 단어의 감성을 나타내는 감성 지수와 객관성을(감성과 반대) 나타내는 객관성 지수를 가지고 있다.   \n","1. 감성 지수  \n","*   긍정 감정 지수\n","*   부정 감정 지수 \n","2. 객관성 지수  \n","\n","\n","*   1 : 어떤 단어가 전혀 감성적이지 않다.  (이때 감성 지수는 0)\n","*   0 \n","\n","\n","\n","\n"],"metadata":{"id":"MtTv8tmMm2js"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import sentiwordnet as swn"],"metadata":{"id":"wSKAK5iJm1b9","executionInfo":{"status":"ok","timestamp":1651475626884,"user_tz":-540,"elapsed":2,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["father = swn.senti_synset('father.n.01')\n","\n","print('father 긍정감성 지수:',father.pos_score())\n","print('father 부정감성 지수:',father.neg_score())\n","print('father 객관성 지수:', father.obj_score())\n","print('\\n')\n","fabulous = swn.senti_synset('fabulous.a.01')\n","print('fabulous 긍정감성 지수: ',fabulous.pos_score())\n","print('fabulous 부정감성 지수: ',fabulous.neg_score())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezrXtWKynjar","executionInfo":{"status":"ok","timestamp":1651475776901,"user_tz":-540,"elapsed":386,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"71c93ce1-5e23-4d76-87a3-780dcbca3614"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["father 긍정감성 지수: 0.0\n","father 부정감성 지수: 0.0\n","father 객관성 지수: 1.0\n","\n","\n","fabulous 긍정감성 지수:  0.875\n","fabulous 부정감성 지수:  0.125\n"]}]},{"cell_type":"markdown","source":["SentiWordNet을 이용한 감상평 감성 분석"],"metadata":{"id":"e0EE4ynRoKjO"}},{"cell_type":"markdown","source":["1. 문서를 문장 단위로 분해\n","2. 다시 문장을 단어 단위로 토큰화하고 품사 태깅\n","3. 품사 태깅된 단어 기반으로 synset 객체와 senti_synset 객체를 생성\n","4. Senti_synset에서 긍정 감성/부정 감성 지수를 구하고 이를 모두 합산해 특정 임계치 이상일 때 긍정 감성으로, 그렇지 않을 때는 부정 감성으로 결정"],"metadata":{"id":"4p2S7pjLoP9y"}},{"cell_type":"markdown","source":["품사 태깅을 수행하는 내부 함수를 생성"],"metadata":{"id":"0ec0QW-joiTN"}},{"cell_type":"code","source":["from nltk.corpus import wordnet as wn\n","\n","#간단한 NTLK PennTreebank Tag를 기반으로 WordNet 기반의 품사 Tag 로 변환\n","def penn_to_wn(tag):\n","    if tag.startswith('J'):\n","        return wn.ADJ\n","    elif tag.startswith('N'):\n","        return wn.NOUN\n","    elif tag.startswith('R'):\n","        return wn.ADV\n","    elif tag.startswith('V'):\n","        return wn.VERB"],"metadata":{"id":"464MI7UmoIIf","executionInfo":{"status":"ok","timestamp":1651476032945,"user_tz":-540,"elapsed":401,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["문장 -> 단어 토큰 -> 품사 태깅 후에 SentiSynset 클래스를 생성하고 Polarity Score를 합산하는 함수를 생성하겠다."],"metadata":{"id":"FufXLYTWpIFa"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import sentiwordnet as sentiwordnet\n","from nltk import sent_tokenize, word_tokenize, pos_tag"],"metadata":{"id":"qZ71kNCwpGoW","executionInfo":{"status":"ok","timestamp":1651476128638,"user_tz":-540,"elapsed":554,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["def swn_polarity(text):\n","    #감성 지수 초기화\n","    sentiment = 0.0\n","    tokens_count = 0\n","\n","    lemmatizer = WordNetLemmatizer()\n","    raw_sentences = sent_tokenize(text)\n","    #분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산\n","    for raw_sentence in raw_sentences:\n","        #NTLK 기반의 품사 태깅 문장 추출\n","        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n","        for word, tag in tagged_sentence:\n","\n","            #WordNet 기반 품사 태깅과 어근 추출\n","            wn_tag = penn_to_wn(tag)\n","            if wn_tag not in (wn.NOUN,wn.ADJ,wn.ADV):\n","                continue\n","            lemma = lemmatizer.lemmatize(wordpos=wn_tag)\n","            if not lemma:\n","                continue\n","            #어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성\n","            synsets = wn.synsets(lemma,pos=wn_tag)\n","            if not synsets:\n","                continue\n","            #sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n","            #모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산.\n","            synset = synsets[0]\n","            swn_synset = swn.senti_synset(synset.name())\n","            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n","            tokens_count += 1\n","    if not tokens_count:\n","        return 0\n","\n","    #총 score 가 0 이상일 경우 긍정(positive) 1, 그렇지 않을 경우 부정(negative) 0 반환\n","    if sentiment >= 0:\n","        return 1\n","    return 0\n"],"metadata":{"id":"nIdm67Brpd9w","executionInfo":{"status":"ok","timestamp":1651476728507,"user_tz":-540,"elapsed":576,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["train_df['preds'] = train_df['review'].apply(lambda x:swn_polarity(x))\n","y_target = train_df['sentiment'].values\n","preds = train_df['preds'].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"id":"yiMfm-KirwS8","executionInfo":{"status":"error","timestamp":1651476795458,"user_tz":-540,"elapsed":412,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"6bf6ecdf-4ea9-43b6-f9d7-2d3bf4fb3fc1"},"execution_count":63,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-4fdc842a713d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preds'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mswn_polarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"]}]},{"cell_type":"markdown","source":["###VADER를 이용한 감성 분석"],"metadata":{"id":"3YdZUc5rthcG"}},{"cell_type":"markdown","source":["compound score : 부정 감성 지수 , 중립적인 감성 지수, 긍정 감성 지수를 적절히 조합해 -1과 1 사이의 감성 지수를 표현한 값  \n","0.1 이상이면 긍정 감성, 그 이하면 부정 감성 "],"metadata":{"id":"QqwpWZMKtoUY"}},{"cell_type":"code","source":["from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","senti_analyzer = SentimentIntensityAnalyzer()\n","senti_scores = senti_analyzer.polarity_scores(train_df['review'][0])\n","print(senti_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"YsUTIexrvUcT","executionInfo":{"status":"error","timestamp":1651477759701,"user_tz":-540,"elapsed":621,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"56a1de58-3043-4b9b-f389-21a930a1a7e9"},"execution_count":66,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-711f47562158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msenti_analyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msenti_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msenti_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"]}]},{"cell_type":"code","source":["def vader_polarity(review, threshold=0.1):\n","    analyzer = SentimentIntensityAnalyzer()\n","    scores = analyzer.polarity_scores(review)\n","\n","    #compound 값에 기반해 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환\n","    agg_score = scores['compound']\n","    final_sentiment = 1 if agg_score >= threshold else 0\n","    return final_sentiment\n","\n","#apply lambda 식을 이용해 레코드별로 vader_polarity()를 수행하고 결과를 'vader_preds'에 저장\n","review_df['vader_preds'] = review_df['review'].apply(lambda x: vader_polarity(x,0.1))\n","y_target = review_df['sentiment'].values\n","vader_preds = review_df['vader_preds'].value_counts\n","\n","print(confusion_matrix(y_target,vader_preds))\n","print('정확도:',np.round(accuracy_score(y_target,vader_preds),4))\n","print('정밀도:',np.round(precision_score(y_target,vader_preds),4))\n","print('재현율:',np.round(recall_score(y_target,vader_preds),4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"nnoino_ysAy0","executionInfo":{"status":"error","timestamp":1651477624093,"user_tz":-540,"elapsed":585,"user":{"displayName":"­신선민(자연과학대학 통계학과)","userId":"15538581907388309584"}},"outputId":"e5349a4f-c123-4eb9-c5e9-2a9d70d45b13"},"execution_count":64,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-15dbd1059fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#apply lambda 식을 이용해 레코드별로 vader_polarity()를 수행하고 결과를 'vader_preds'에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vader_preds'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvader_polarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mvader_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vader_preds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-64-15dbd1059fc2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#apply lambda 식을 이용해 레코드별로 vader_polarity()를 수행하고 결과를 'vader_preds'에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vader_preds'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvader_polarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mvader_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vader_preds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-64-15dbd1059fc2>\u001b[0m in \u001b[0;36mvader_polarity\u001b[0;34m(review, threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvader_polarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#compound 값에 기반해 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'SentimentIntensityAnalyzer' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"4QXxQtTivLDY"},"execution_count":null,"outputs":[]}]}